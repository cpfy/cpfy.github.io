# Design and Analysis of Algorithms

## Lecture1ï¼šIntroduction

ç•¥

## Lecture 2: Asymptotic Notations and Recurrences

+ Asymptotic Notationsï¼ˆæ¸è¿›è®°å·ï¼‰

  + Big-Oh
  + Big-Omega
  + Big-Theta

+ Solving Recurrences

  + Recursion tree methodï¼ˆé€’å½’æ ‘æ³•ï¼‰

  + Substitution methodï¼ˆæ›¿ä»£æ³•ï¼‰

  + Master method and master Theoremï¼ˆä¸»æ–¹æ³•ï¼‰

    å¯¹äºé€’æ¨å¼$T(n)=aT(\lceil \frac{n}{b} \rceil)+O(n^d)$ï¼Œå…¶ä¸­$a>0, b>1,d \geq 0$ï¼ŒT(n)çš„å¤æ‚åº¦ä¸ºï¼š
    $$
    T(n)= \left\{ \begin{array}{rcl}
    O(n^d), & if \ d>\log_ba	\\
    O(n^d \log n), & if \ d=\log_ba	\\
    O(n^{\log_ba}), & if \ d<\log_ba	\\
    \end{array}\right.
    $$
    

## Lecture 3ï¼šMaximum Contiguous Subarray Problem and Counting Inversion Problem

+ Introduction to Part I
  
+ Divide-and-conquer (D&C) ï¼š**åˆ†æ²»æ€æƒ³**
  
+ Maximum Contiguous Subarray Problemï¼ˆæœ€å¤§è¿ç»­å­æ•°ç»„é—®é¢˜ï¼‰

  + A brute force algorithmï¼ˆæš´åŠ›è§£æ³•ï¼‰

    $O(n^3)$

  + A data-reuse algorithmï¼ˆé‡å¤åˆ©ç”¨å·²ç®—å‡ºçš„æ•°æ®ï¼‰

    $O(n^2)$

  + A divide-and-conquer algorithmï¼ˆåˆ†æ²»è§£æ³•ï¼‰

    $O(nlogn)$

  + Kadaneâ€˜s algorithmå¯ä»¥é™åˆ°$O(n)$

+ Counting Inversions Problemï¼ˆé€†åºè®¡æ•°é—®é¢˜ï¼‰

  + A brute force algorithm

    $O(n^2)$

  + A divide-and-conquer algorithm

    + åˆå¹¶æ€è·¯-1ï¼šFor each element b âˆˆ B, binary search in A to find how many elements in A are greater than b.

      ï¼ˆåœ¨Aã€Bæœ‰åºæ¡ä»¶ä¸‹ï¼Œå¯¹Bä¸­æ¯ä¸ªå…ƒç´ äºŒåˆ†æŸ¥æ‰¾Aä¸­å‡ ä¸ªå…ƒç´ æ¯”å®ƒå¤§ï¼‰

      **å¤æ‚åº¦ï¼š**$O(nlogn)$

    + æ”¹è¿›çš„åˆå¹¶æ€è·¯-2ï¼šCompare ai and bj.
      If ai < bj, then ai is not inverted with any element left in B.
      If ai > bj, then bj is inverted with every element left in A.
      Append smaller element to sorted list C.

      ï¼ˆè¾¹scanè¾¹è®¡æ•°ï¼ŒåŒæ—¶æ–°çš„list Cå¯é¡ºä¾¿sortäº†ï¼‰

      **å¤æ‚åº¦ï¼š**$O(n)$ï¼›ç®—ä¸Šå…¨éƒ¨çš„é€’å½’åˆ™ä¸ºï¼š$O(nlogn)$

## Lecture 4ï¼šPolynomial Multiplication_Quicksort

+ Polynomial Multiplication Problemï¼ˆå¤šé¡¹å¼ä¹˜æ³•é—®é¢˜ï¼‰

  + Problem definition 

  + A brute force algorithm

    æ­£å¸¸ä¸¤å¤šé¡¹å¼ç›¸ä¹˜ï¼Œå¤æ‚åº¦ï¼š$O(n^2)$

  + A first divide-and-conquer algorithm

    + è®¾å®šï¼š
      $$
      A_0(x)=a_0+a_1x+...+a_{\frac{n}{2}-1}x^{\frac{n}{2}-1}	\\
      A_1(x) = a_{\frac{n}{2}}+ a_{\frac{n}{2}+1}x+...+a_nx^{\frac{n}{2}}	\\
      A(x) = A_0(x)+A_1(x)x^{\frac{n}{2}}	\\
      Similarly, \ B(x) = B_0(x)+B_1(x)x^{\frac{n}{2}}	\\
      $$

    + äºæ˜¯ï¼Œ$A(x)B(x) = A_0(x)B_0(x) + A_0(x)B_1(x)x^{\frac{n}{2}}+A_1(x)B_0(x)x^{\frac{n}{2}}+A_1(x)B_1(x)x^n$

    + å¤æ‚åº¦è®¡ç®—ï¼š$T(n) = 4T(n/2)+n$ï¼›$Total = O(n^2)$

  + An improved divide-and-conquer algorithm

    + ä»¤ï¼š
      $$
      Y = (A_0+A_1)(B_0+B_1)	\\
      U = A_0B_0	\\
      Z = A_1B_1	\\
      A_0B_1+A_1B_0 = Y - U - Z
      $$

    + $Total = O(n^{log3})$

  + Analysis of the divide-and-conquer algorithm

    Fast Fourier Transformï¼ˆFFTï¼‰ç®—æ³•å¯è¾¾åˆ°ï¼š$O(nlogn)$

+ Quicksort Problemï¼ˆå¿«é€Ÿæ’åºé—®é¢˜ï¼‰

  + Basic partition 
  + Randomized partition and randomized quicksort
  + Analysis of the randomized quicksort

## Lecture 4+: Quicksort, Heapsort and Comparison-based Lower Bound for Sorting

+ Introduction to Part II

  ä¸‰ç§å‡ä¸º$O(n\log n)$

+ Quicksort Problem

  + Basic partition 

  + Randomized partition and randomized quicksort

    ä¸ä¸Šé¢ç›¸æ¯”æ¯æ¬¡é€‰å–éšæœºä½ç½®åŸºå‡†æ•°ï¼Œæ‰€éœ€æ—¶é—´ä¸ä¾èµ–äºè¾“å…¥

  + Analysis of the randomized quicksort

    è®¡ç®—Expectionçš„p152é¡µæå…¶ç²¾å½©

+ Heapsort Problem

  + Priority Queues

  + (Binary) Heap

    æ’å…¥ã€å–æœ€å°ï¼ˆæœ€å¤§ï¼‰å€¼å‡ä¸º$O(\log n)$

  + Heapsort

+ Lower Bound for Comparison-based Sorting

  + Objective

    å¯è¯æ˜comparisionä¸‹çš„æ’åºæé™æ˜¯$O(n \log n)$ï¼Œè§p274

  + Decision Tree Model

## Lecture 5: 0-1 Knapsack and Rod Cutting Problems

### 0-1 Knapsack Problemï¼ˆ0-1èƒŒåŒ…ï¼‰

* Problem Definition

  nä¸ªèƒŒåŒ…ï¼Œä»·å€¼åˆ†åˆ«$v_i$ï¼Œé‡é‡åˆ†åˆ«$w_i$ï¼Œé‡é‡ä¸è¶…è¿‡Wçš„æƒ…å†µä¸‹æ±‚æœ€å¤§ä»·å€¼ã€‚

* A Bruteforce Algorithm

  $V[i,w]=max(V[i-1,w], v_i+V[i-1,w-w_i])$

  é€’å½’æ±‚è§£ï¼š$KnapsackSR(i,w)=max\{ KnapsackSR(i-1,w), v_i + KnapsackSR(i-1,w-w_i) \}$

  **å¤æ‚åº¦**ï¼š$\Omega(2^n)$

* A Dynamic Programming Algorithm

  æ ¸å¿ƒæ€æƒ³ï¼šè‡ªåº•å‘ä¸Šã€å¡«è¡¨

  **å¤æ‚åº¦**ï¼š$O(nW)$

* Analysis of DP Algorithm

### Rod Cutting Problemï¼ˆé’¢æ¡åˆ‡å‰²ï¼‰

* Problem Definition

  ä¸€é’¢æ¡ï¼Œä¸åŒé•¿åº¦çš„ä»·å€¼$p_i$ç¡®å®šï¼Œåˆ‡å‰²æœ€å¤§ä»·å€¼ã€å¦‚ä½•åˆ‡å‰²æ€»ä»·å€¼æœ€å¤§ã€‚

* A Bruteforce Algorithm

  æš´åŠ›çš„é€’å½’ï¼š$r_n=max(p_n, r_1+r_{n-1}, r_2+r_{n-2}, ..., r_{n-1}+r_1)$

  ç¨ç®€åŒ–ç‰ˆæœ¬ï¼š$r_n=\mathop{max}\limits_{1 \leq i \leq n} (p_i+r_{n-i})$

* A Dynamic Programming Algorithm

  è‡ªåº•å‘ä¸Šè®¡ç®—$r[n]$ï¼Œå¯¹æ¯ä¸€ä¸ª$j$ï¼Œiä»1åˆ°$j$éå†ï¼Œ$q \leftarrow max(q, p[i]+r[j-i])$ï¼Œå…±è®¡ç®—$j$æ¬¡

  **å¤æ‚åº¦**ï¼š$O(n^2)$

## Lecture 6: Chain Matrix Multiplication and Longest Common Subsequence Problem

### Chain Matrix Multiplication Problemï¼ˆçŸ©é˜µé“¾ä¹˜æ³•ï¼‰

+ Review of Matrix Multiplication

  é—®é¢˜å®šä¹‰ï¼š$A_1A_2...A_n$çŸ©é˜µåºåˆ—ï¼Œæ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ä¹˜æ³•é¡ºåºï¼ˆåŠ æ‹¬å·ï¼‰ä½¿å¾—æ€»è¿ç®—æ•°æœ€å°

+ The Chain Matrix Multiplication Problem

+ A Dynamic Programming Algorithm

  é€’æ¨å…¬å¼ï¼š$m[i,j]= \mathop{min}\limits_{i \leq k < j}(m[i,k]+m[k+1,j]+p_{i-1}p_kp_j) $

  **å¤æ‚åº¦**ï¼š$O(n^3)$

### Longest Common Subsequence Problemï¼ˆæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰

+ Longest Common Subsequence Problem
  $$
  d_{i,j}= \left\{ \begin{array}{rcl}
  d_{i-1,j-1}+1, & if \ x_i=y_j	\\
  max\{d_{i-1,j},d_{i,j-1}\}, & if \ x_i\neq y_j	\\
  \end{array}\right.
  $$

+ Longest Common Substring Problem
  $$
  d_{i,j}= \left\{ \begin{array}{rcl}
  d_{i-1,j-1}+1, & if \ x_i=y_j	\\
  0, & if \ x_i\neq y_j	\\
  \end{array}\right.
  $$
  
+ **å¤æ‚åº¦**ï¼šå‡ä¸º$O(n^2)$

## Lecture 7: Minimum Edit Distance Problem

### Minimum Edit Distance Problemï¼ˆæœ€å°ç¼–è¾‘è·ç¦»ï¼‰

+ Motivations and Applications

+ Problem Definition

  Given two strings X=(x1, x2,â€¦, xm) and Y=(y1, y2,â€¦, yn), the edit distance is the smallest number of following edit operations to turn X into Y:

  + Insertion: add a letter
  + Deletion: remove a letter
  + Substitution: replace a character with another one.

+ The Dynamic Programming Algorithm

  å°†$X[1...i]$è½¬å˜ä¸º$Y[1...j]$åˆ†ä¸‰ç§æƒ…å†µï¼š

  + Case 1: Turn $X[1...i-1]$è½¬å˜ä¸º$Y[1...j]$ å¹¶åˆ é™¤ $X[i]$

    Example 1 : MED (cxy-> dab) =MED (cx-> dab) + 1

  + Case 2: Turn $X[1...i]$è½¬å˜ä¸º$Y[1...j-1]$ å¹¶æ’å…¥ $Y[j]$

    Example 2: MED (cxy-> dab) = MED (cxy-> da) +1

  + Case 3: Turn $X[1...i-1]$è½¬å˜ä¸º$Y[1...j-1]$  and æ›¿æ¢ $X[i]$ with $Y[j]$ if needed (X[i]+YUij)

    Example 3.1 : MED (cxy-> dab) =MED (cx-> da) +1

    Example 3.2: MED (cxy-> day) =MED (cx-> da)D[i-1,j+1D[i,j]=minD[i,j-1]+1D[i-1,j-1] +10 if X[i] =Yj](1 otherwise.

  åˆ™é€’æ¨å…¬å¼ä¸ºï¼š
  $$
  D[i.j]=min
  \begin{cases}
  D[i-1,j]+1 \\
  D[i,j-1]+1 \\
  D[i-1,j-1]+
  \begin{cases}
  0 & \text{if X[i]=Y[j]}\\
  1 & \text{otherwise}
  \end{cases}
  \end{cases}
  $$
  ç”¨ä¸€ä¸ªè¾…åŠ©æ•°ç»„$p[i,j]$æ¥å­˜ä½ç½®

  **å¤æ‚åº¦**ï¼š$O(mn)$

## Lecture 9: Fraction Knapsack, Activity Selection and Huffman Coding Problems

### The Fractional Knapsack Problemï¼ˆåˆ†æ•°èƒŒåŒ…é—®é¢˜ï¼‰

+ Problem Definition

+ A Greedy Algorithm and correctness

  å…ˆ$O(n\log n)$æŒ‰ä»·å€¼æ’åºï¼Œä¹‹å$O(n)$æŒ‰ä»·å€¼é€‰ç‰©å“ï¼Œæœ€åè¯æ˜Correctness

### The Activity Selection Problemï¼ˆæ´»åŠ¨é€‰æ‹©é—®é¢˜ï¼‰

#### Problem Definition

#### A Greedy Algorithm and correctness

* è´ªå¿ƒçš„é€‰æ³•ï¼šé€‰æ‹©ç»“æŸæ—¶é—´æœ€æ—©çš„æ´»åŠ¨

* ç®—æ³•è¿‡ç¨‹ï¼šå…ˆ$O(n\log n)$æŒ‰ç»“æŸæ—¶é—´æ’åºï¼Œä¹‹åæœ€æ¯æ¬¡é€‰ç»“æŸæ—¶é—´æœ€æ—©çš„ï¼ˆå½“å‰ç¬¬ä¸€ä¸ªï¼‰ï¼Œå»é™¤å†²çªçš„æ´»åŠ¨ã€‚


##### è¯æ˜Correctness

åŸºæœ¬æ€æƒ³ï¼šWe can convert any other optimal solution(ğ‘ƒâ€²) to the greedy algorithm solution(ğ‘ƒ)

è¿‡ç¨‹ï¼š

* Compare the activities in ğ‘ƒâ€² and ğ‘ƒ from left to right
* If they match in the selected activity  â†’  skip
* If they do not match, we can replace the activity in ğ‘ƒâ€² by that in ğ‘ƒ because the one in ğ‘ƒ finish first

ä¾‹å¦‚ï¼Œåœ¨ä¸‹å›¾ä¸­ï¼Œè¯æ˜æœ€ä¼˜è§£å¯ä»¥â€œæ— æŸâ€è½¬åŒ–ä¸ºç®—æ³•è§£ï¼Œä¹‹å‰ã€ä¹‹åçš„æ—¶é—´å‡ä¸ä¼šå½±å“

![image-20211105161531971](ç®—æ³•è®¾è®¡ä¸åˆ†æ è¯¾ç¨‹ç¬”è®°.assets/image-20211105161531971.png)

#### Extended: Weighted Activity Selection

æ¯ä¸€é¡¹æ´»åŠ¨åŠ å…¥æƒé‡$w_i$ï¼Œæ‰¾æ€»æƒé‡å’Œæœ€å¤§çš„æ´»åŠ¨åºåˆ—

##### ç®—æ³•æ€æƒ³

* å®šä¹‰$p(j)$ ä¸ºæœ€å¤§çš„ç´¢å¼•$i$ä½¿å¾—æ´»åŠ¨$a_i$åœ¨ç¬¬$j$ä¸ªæ´»åŠ¨å‰ä¸”ä¸å†²çª

* åŠ¨æ€è§„åˆ’é€’æ¨å…³ç³»ï¼š
  $$
  OPT(j)=
  \begin{cases}
  0, &\text{if j=0}	\\
  max\{ OPT(j-1), w_j + OPT(p(j)) \}, &\text{if j>0}	\\
  \end{cases}
  $$

* ä¸€ä¸ªä¾‹å­

  ![image-20211105162615302](ç®—æ³•è®¾è®¡ä¸åˆ†æ è¯¾ç¨‹ç¬”è®°.assets/image-20211105162615302.png)

### The Huffman Coding Problemï¼ˆéœå¤«æ›¼ç¼–ç é—®é¢˜ï¼‰

#### Problem Definition

* ä¸€ä¸ªæ£€æµ‹åç¼€çš„ç®—æ³•å¯ä»¥æ£€æµ‹æ˜¯å¦æ»¡è¶³å”¯ä¸€å¯è¯‘ï¼Œ1949å¹´

#### A Greedy Algorithm

è´ªå¿ƒæ€æƒ³ï¼šæ¯æ¬¡é€‰æœ€å°çš„xï¼Œyç»„æˆå­æ ‘ï¼Œæ›´æ–°æƒé‡ä¸ºx+y

#### æ­£ç¡®æ€§è¯æ˜



## Lecture 9.x 

è¡¥å……äº†ä¸€éƒ¨åˆ†å…³äºé¦™å†œçš„ä¿¡æ¯ç†µç¼–ç å…¬å¼ã€Krash-McMilianå…¬å¼åŠè¯æ˜

### ä¿¡æ¯ç†µ

$$
H(X)=\sum_iP(x_i)I(x_i)=-\sum_iP(x_i)\log bP(x_i)
$$

åœ¨è¿™é‡Œbæ˜¯å¯¹æ•°æ‰€ä½¿ç”¨çš„åº•ï¼Œé€šå¸¸æ˜¯2,è‡ªç„¶å¸¸æ•°eï¼Œæˆ–æ˜¯10ã€‚å½“b = 2ï¼Œç†µçš„å•ä½æ˜¯bitï¼›

### Kraftâ€“McMillanå…¬å¼

è®¾ç¬¦å·è¡¨ä¸­çš„åŸå§‹ç¬¦å·ä¸º
$$
S=\{ s_1,s_2,...,s_n \}
$$
åœ¨å¤§å°ä¸º$r$çš„å­—ç¬¦é›†ä¸Šç¼–ç ä¸ºå”¯ä¸€å¯è§£ç¼–ç çš„ç å­—é•¿åº¦ä¸º
$$
l_1,l_2,...,l_n
$$
åˆ™
$$
\sum_{i=1}^n r^{-l_i} \leq 1
$$
åä¹‹ï¼Œç»™å®šä¸€ä¸ªæ»¡è¶³ä¸Šè¿°ä¸ç­‰å¼çš„è‡ªç„¶æ•°é›†åˆ$l_1,l_2,...,l_n$ , åˆ™åœ¨å¤§å°ä¸º$r$å­—ç¬¦é›†ä¸Šï¼Œå­˜åœ¨ä¸€ç»„å”¯ä¸€å¯è§£ç¼–ç ç¬¦åˆç›¸åº”çš„ç å­—é•¿åº¦ã€‚

## Lecture 10: Review of BFS/DFS, Topological Sort and Strongly Connected Components  

### å…³äºå›¾çš„æ¦‚å¿µ

#### BFS

#### DFS

### æ‹“æ‰‘æ’åº

Topological Sort

#### Topological Sort Algorithm ç®—æ³•

æ‹“æœ´æ’åºï¼šæ¯ä¸ªå…¥åº¦0åŠ è¿›å»ï¼Œåˆ é™¤

#### Topological Sort Algorithm å¤æ‚åº¦åˆ†æ

* å¤æ‚åº¦$O(V+E)$

æŒ‰DFSå®Œæˆæ—¶é—´çš„å€’åºæ’åˆ—

è€ƒè™‘ä¸¤é¡¶ç‚¹u -> v

* è‹¥vç°è‰²ï¼Œåˆ™vä¸ºuç¥–å…ˆï¼Œå½¢æˆç¯å›¾ï¼ŒçŸ›ç›¾ï¼
* è‹¥vç™½è‰²ï¼Œæ­£å¸¸è¾“å‡º
* è‹¥vé»‘è‰²

### å¼ºè¿é€šåˆ†é‡

#### æ¦‚å¿µ

è®¾$G= (V, E)$æ˜¯ä¸€ä¸ªæœ‰å‘å›¾ã€‚

Gçš„ä¸€ä¸ªå¼ºè¿é€šåˆ†é‡(SCC)æ˜¯Gçš„ä¸€ä¸ªå­é›†çš„Vä½¿å¾—ï¼š

å¯¹ä»»æ„ä¸¤ä¸ªé¡¶ç‚¹$u,v\in S$ï¼Œæ—¢æœ‰ä¸€æ¡u-vçš„è·¯å¾„ï¼Œä¹Ÿæœ‰ä¸€æ¡v-uçš„è·¯å¾„ã€‚

Sæ˜¯ä¸€ä¸ªæœ€å¤§é›†ï¼Œä¸èƒ½åœ¨ä¸è¿èƒŒä¸Šè¿°æ¡ä»¶çš„æƒ…å†µä¸‹å‘å…¶ä¸­åŠ å…¥æ›´å¤šçš„ç»“ç‚¹Våˆ°Sä¸­

#### æ±‚è§£SCCçš„ç®—æ³•

ç”¨åˆ°ä¸€ä¸ªåè½¬å›¾G^Rçš„æ€æƒ³

ã€æ‘˜è‡ªwikiã€‘

1. å¯¹æœ‰å‘å›¾Gå–é€†ï¼Œå¾—åˆ°Gçš„åå‘å›¾$G^R$
2. åˆ©ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢æ±‚å‡º$G^R$çš„é€†åæ’åº
3. å¯¹GæŒ‰ç…§ä¸Šè¿°é€†åæ’åºçš„åºåˆ—è¿›è¡Œæ·±åº¦ä¼˜å…ˆæœç´¢
4. åŒä¸€ä¸ªæ·±åº¦ä¼˜å…ˆæœç´¢é€’å½’å­ç¨‹åºä¸­è®¿é—®çš„æ‰€æœ‰é¡¶ç‚¹éƒ½åœ¨åŒä¸€ä¸ªå¼ºè¿é€šåˆ†é‡å†…

#### ç®—æ³•è¿‡ç¨‹ Finding SCCs

Step 1: Obtain the reverse graph GR by reversing the directions of all the edges in G.
Step 2: Perform DFS on GR, and obtain the sequence LR that the vertices in GR turn black (i.e., whenever a vertex is popped out of the stack, append it to LR). Obtain L as the reverse order of LR.
Step 3: Perform DFS on the original graph G by obeying the following rules:
Rule 1: Start the DFS at the first vertex of L.
Rule 2: Whenever a restart is needed, start from the first vertex of L that is still white.
Output the vertices in each DFS-tree as an SCC.

#### å¤æ‚åº¦åˆ†æ

Steps 1 and 2 obviously require only ğ‘‚(|ğ‘‰|+|ğ¸|) time.

Regarding Step 3, the DFS itself takes ğ‘‚(|ğ‘‰|+|ğ¸|) time, but we still need to discuss the time to implement Rule 2. Namely, whenever DFS needs a restart, how do we find the first white vertex in L efficiently? This will be left as an exercise.

Hence, the overall execution time is $O(|V|+|E|)$. 

#### æ­£ç¡®æ€§è¯æ˜

ä¹Ÿå°±æ˜¯è¯´ï¼Œç¬¬ä¸€è½®å¯¹äºGRçš„DFSä¸­ï¼ŒS2ä¸­æœ€åä¸€ä¸ªé¡¶ç‚¹ç»“æŸæ—¶é—´ä¸€å®šä¼šæ™šäºS1çš„æœ€åä¸€ä¸ªé¡¶ç‚¹ç»“æŸæ—¶é—´ï¼Œè¿™æ ·åœ¨LRä¸­S2çš„æœ€åä¸€ä¸ªé¡¶ç‚¹æ¯”S1çš„æ›´é åï¼Œåœ¨Lä¸­æ›´é å‰ã€‚

## Lecture 11: Minimum Spanning Trees

Review to Part V

### æœ€å°ç”Ÿæˆæ ‘

å®šä¹‰ã€æ¦‚å¿µç­‰

### Primâ€™s algorithm

#### æ ¸å¿ƒæ€æƒ³

#### ç®—æ³•å†…å®¹

æ­¥éª¤0:é€‰æ‹©ä»»æ„å…ƒç´ r;è®¾ç½®S=frå’ŒA=0ã€‚å°†rä½œä¸ºç”Ÿæˆæ ‘çš„æ ¹

æ­¥éª¤1:æ‰¾åˆ°ä¸€æ¡æœ€è½»çš„è¾¹ï¼Œä½¿ä¸€æ¡ç«¯ç‚¹åœ¨Sä¸­ï¼Œå¦ä¸€æ¡ç«¯ç‚¹åœ¨V\ sä¸­å°†è¿™æ¡è¾¹æ·»åŠ åˆ°aä¸­ï¼Œå°†å®ƒçš„(å…¶ä»–)ç«¯ç‚¹æ·»åŠ åˆ°Sä¸­ã€‚

æ­¥éª¤2å¦‚æœV\S=0ï¼Œåˆ™åœæ­¢ç”Ÿæˆæ ‘è¾“å‡º(æœ€å°)a;å¦åˆ™ï¼Œè¯·æ‰§è¡Œæ­¥éª¤1ã€‚

#### å¤æ‚åº¦åˆ†æ

ç®€å•å›é¡¾ä¼˜å…ˆé˜Ÿåˆ—

ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—PriQueueçš„æƒ…å†µä¸‹ï¼š

* å¯¹æ¯ä¸€ä¸ªVéœ€è¦$O(\log V)$çš„æ—¶é—´æŸ¥è¯¢æœ€å°çš„ï¼›
* å¯¹æ¯ä¸€ä¸ªEéœ€è¦$O(\log V)$çš„æ—¶é—´åœ¨ä¼˜å…ˆé˜Ÿåˆ—ä¸ŠDecrease-Keyï¼›

æ€»å¤æ‚åº¦ä¸ºï¼š
$$
O(V\log V+E\log V) = O((V+E)\log V)=O(E\log V)
$$

### Kruskalâ€™s algorithm

The idea
The algorithm
The Disjoint Set Union-Find data structure
Analysis for Kruskalâ€™s algorithm
