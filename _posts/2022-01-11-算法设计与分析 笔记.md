Design and Analysis of Algorithms

## ç¬¬1èŠ‚ å¼•è¨€

Lecture1ï¼šIntroduction

### ç®—æ³•çš„æ¦‚å¿µ

è®¡ç®—é—®é¢˜ï¼ˆComputational Problemï¼‰ï¼šæ˜¯æœŸæœ›çš„è¾“å…¥-è¾“å‡ºå…³ç³»çš„ä¸€ç§è§„èŒƒ

é—®é¢˜å®ä¾‹ï¼ˆProblem Instanceï¼‰ï¼šA problem instance is any valid input to the problem

ç®—æ³•ï¼šæ˜¯ä¸€ä¸ªå®šä¹‰è‰¯å¥½çš„è®¡ç®—è¿‡ç¨‹ï¼Œå®ƒå°†è¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºï¼Œä»¥å®ç°æœŸæœ›çš„è¾“å…¥-è¾“å‡ºå…³ç³»ã€‚

* å¯¹äºæ¯ä¸ªè¾“å…¥å®ä¾‹ï¼Œæ­£ç¡®çš„ç®—æ³•åœ¨æ­£ç¡®çš„è¾“å‡ºæ—¶åœæ­¢ã€‚æˆ‘ä»¬å¯ä»¥è¯´è¿™ä¸ªç®—æ³•è§£å†³äº†è¿™ä¸ªé—®é¢˜

### åˆ†æä¸€ä¸ªç®—æ³•

é¢„æµ‹èµ„æºåˆ©ç”¨ï¼šç©ºé—´ã€æ—¶é—´å¤æ‚åº¦

è¡¡é‡è¿è¡Œæ—¶é—´ï¼šåŸºæœ¬æ“ä½œï¼ˆprimitive operationsï¼‰æ•°é‡

#### ä¸‰ç§åˆ†æ

æœ€å·®æƒ…å†µåˆ†æï¼ŒæœŸæœ›æƒ…å†µåˆ†æï¼Œå¹³å‡æƒ…å†µåˆ†æ

* Best Caseï¼šç»™å®šå¤§å°nçš„å®ä¾‹ï¼Œå…¶ç»“æœæ˜¯æœ€å¿«çš„è¿è¡Œæ—¶é—´ã€‚
  * æ— ç”¨ï¼ŒClearly useless 
* Worst Caseï¼šç»™å®šå¤§å°nçš„å®ä¾‹å¯¼è‡´è¿è¡Œæ—¶é—´æœ€æ…¢ã€‚
  * **æœ€å¸¸ä½¿ç”¨**ï¼ŒCommonly used
* Average Caseï¼šå¯¹äºç»™å®šçš„å¤§å°ï¼Œæ‰€æœ‰å¯èƒ½çš„å®ä¾‹çš„å¹³å‡è¿è¡Œæ—¶é—´ï¼Œå‡è®¾å®ä¾‹ä¸Šæœ‰æŸç§æ¦‚ç‡åˆ†å¸ƒã€‚
  * æœ‰æ—¶ä½¿ç”¨

#### åˆ†æè¿è¡Œæ—¶é—´

ä¸¾äº†ä¸€äº›ä¾‹å­

## ç¬¬2èŠ‚ æ¸è¿›è®°å·ä¸é€’å½’

Lecture 2: Asymptotic Notationsï¼ˆæ¸è¿›è®°å·ï¼‰ and Recurrences

### æ¸è¿›è®°å·

Asymptotic Notationsï¼ˆæ¸è¿›è®°å·ï¼‰

#### Big-Oh

ä»£è¡¨æ¸è¿‘ä¸Šç•Œ

##### å®šä¹‰

$f(n) = O(g(n))$ ï¼šå­˜åœ¨å¸¸æ•° $c > 0$ åŠ $n_0$ï¼Œä½¿å¾—å¯¹äº $n>n_0$ æ—¶ï¼Œ$f(n)<c\cdot g(n)$

##### ä¸€äº›ä¾‹å­

$$
\log(n!)=\log(n)+...+\log(1)=O(n\log n)
$$

è°ƒå’Œçº§æ•°ï¼ˆHarmonic Seriesï¼‰
$$
\sum_{i=1}^n \frac{1}{i}=O(\log n)
$$
ç®€å•è¯æ˜ï¼ˆp29ï¼‰ï¼š
$$
\begin{align}
\sum_{i=1}^n \frac{1}{i}
&=
\frac{1}{1}+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+\frac{1}{8}+\frac{1}{9}+\frac{1}{10}+...+\frac{1}{n}\\
&<
\frac{1}{1}+\frac{1}{2}+\frac{1}{2}+\frac{1}{4}+\frac{1}{4}+\frac{1}{4}+\frac{1}{4}+\frac{1}{8}+\frac{1}{8}+\frac{1}{8}+...+\frac{1}{n/2}+\frac{1}{n}\\
&=
\frac{1}{1}+2\cdot(\frac{1}{2})+4\cdot(\frac{1}{4})+8\cdot(\frac{1}{8})+...+\frac{n}{2}(\frac{1}{n/2})+\frac{1}{n}\\
&=
\frac{1}{n}+\sum_{j=0}^{\log n-1} 1\\
&=
\log n+\frac{1}{n}\\
&= O(\log n)
\end{align}
$$

#### Big-Omega

ä»£è¡¨æ¸è¿‘ä¸‹ç•Œ

å®šä¹‰ï¼š

$f(n) = \Omega(g(n))$ ï¼šå­˜åœ¨å¸¸æ•° $c > 0$ åŠ $n_0$ï¼Œä½¿å¾—å¯¹äº $n>n_0$ æ—¶ï¼Œ$f(n)\geq c\cdot g(n)$

#### Big-Theta

æ¸è¿‘ç´§ç•Œå®šä¹‰ï¼ˆAsymptotic tight boundï¼‰

å®šä¹‰

$f(n)=\Theta(g(n))$ ï¼š$f(n)=O(g(n))$ ä¸” $f(n)=\Omega(g(n))$

![image-20220109143841024](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220109143841024.png)

#### ç®—æ³•è®¾è®¡ä¸è°ƒä¼˜

è®¾è®¡ä¸€ä¸ª big-Oh running times çš„ç®—æ³•ï¼Œä¹‹åè¿›è¡Œè°ƒä¼˜

### è§£å†³é€’å½’é—®é¢˜

Solving Recurrences

#### é€’å½’æ ‘æ³•

Recursion tree methodï¼ˆé€’å½’æ ‘æ³•ï¼‰

ç”»ä¸€æ£µæ ‘

#### æ›¿ä»£æ³•

Substitution methodï¼ˆæ›¿ä»£æ³•ï¼‰

å‡è®¾ä¸€ä¸ªTï¼ˆnï¼‰ï¼Œå¸¦å…¥å¼å­æ£€éªŒæ˜¯å¦æ­£ç¡®ã€‚æœ‰2ä¸ªä¾‹å­

#### ä¸»æ–¹æ³•

Master method and master Theoremï¼ˆä¸»æ–¹æ³•ï¼‰

å¯¹äºé€’æ¨å¼$T(n)=aT(\lceil \frac{n}{b} \rceil)+O(n^d)$ï¼Œå…¶ä¸­$a>0, b>1,d \geq 0$ï¼ŒT(n)çš„å¤æ‚åº¦ä¸ºï¼š
$$
T(n)= \left\{ \begin{array}{rcl}
O(n^d), & if \ d>\log_ba	\\
O(n^d \log n), & if \ d=\log_ba	\\
O(n^{\log_ba}), & if \ d<\log_ba	\\
\end{array}\right.
$$

éç®€åŒ–å½¢å¼ï¼š

å¯¹å½¢å¦‚ $T(n)=aT(\frac{n}{b})+f(n)$ çš„é€’å½’å¼
$$
T(n)= \left\{ \begin{array}{rcl}
O(f(n)), & if \ f(n)=\Omega(n^{\log_ba+\epsilon})\\
O(n^{\log_ba}\log n), & if \ f(n)=\Theta(n^{\log_ba})\\
O(n^{\log_ba}), & if \ f(n)=O(n^{\log_ba-\epsilon})\\
\end{array}\right.
$$

## ç¬¬3èŠ‚ æœ€å¤§è¿ç»­å­æ•°ç»„ä¸é€†åºè®¡æ•°é—®é¢˜

Lecture 3ï¼šMaximum Contiguous Subarray Problem and Counting Inversion Problem

### ç®€ä»‹

### åˆ†æ²»æ€æƒ³

Divide-and-conquer (D&C) 

### æœ€å¤§è¿ç»­å­æ•°ç»„é—®é¢˜

Maximum Contiguous Subarray Problem

+ A brute force algorithmï¼ˆæš´åŠ›è§£æ³•ï¼‰

  $O(n^3)$

+ A data-reuse algorithmï¼ˆé‡å¤åˆ©ç”¨å·²ç®—å‡ºçš„æ•°æ®ï¼‰

  $O(n^2)$

+ A divide-and-conquer algorithmï¼ˆåˆ†æ²»è§£æ³•ï¼‰

  $O(nlogn)$

+ Kadaneâ€˜s algorithmå¯ä»¥é™åˆ°$O(n)$

### é€†åºè®¡æ•°é—®é¢˜

Counting Inversions Problem

+ A brute force algorithm

  $O(n^2)$

+ A divide-and-conquer algorithm

  + åˆå¹¶æ€è·¯-1ï¼šFor each element b âˆˆ B, binary search in A to find how many elements in A are greater than b.

    ï¼ˆåœ¨Aã€Bæœ‰åºæ¡ä»¶ä¸‹ï¼Œå¯¹Bä¸­æ¯ä¸ªå…ƒç´ äºŒåˆ†æŸ¥æ‰¾Aä¸­å‡ ä¸ªå…ƒç´ æ¯”å®ƒå¤§ï¼‰

    **å¤æ‚åº¦ï¼š**$O(nlogn)$

  + æ”¹è¿›çš„åˆå¹¶æ€è·¯-2ï¼šCompare ai and bj.
    If ai < bj, then ai is not inverted with any element left in B.
    If ai > bj, then bj is inverted with every element left in A.
    Append smaller element to sorted list C.

    ï¼ˆè¾¹scanè¾¹è®¡æ•°ï¼ŒåŒæ—¶æ–°çš„list Cå¯é¡ºä¾¿sortäº†ï¼‰

    **å¤æ‚åº¦ï¼š**$O(n)$ï¼›ç®—ä¸Šå…¨éƒ¨çš„é€’å½’åˆ™ä¸ºï¼š$O(nlogn)$

## ç¬¬4èŠ‚ å¤šé¡¹å¼ä¹˜æ³•/å¿«é€Ÿæ’åº

Lecture 4ï¼šPolynomial Multiplication_Quicksort

### å¤šé¡¹å¼ä¹˜æ³•é—®é¢˜

Polynomial Multiplication Problemï¼ˆå¤šé¡¹å¼ä¹˜æ³•é—®é¢˜ï¼‰

+ Problem definition 

+ A brute force algorithm

  æ­£å¸¸ä¸¤å¤šé¡¹å¼ç›¸ä¹˜ï¼Œå¤æ‚åº¦ï¼š$O(n^2)$

+ A first divide-and-conquer algorithm

  + è®¾å®šï¼š
    $$
    A_0(x)=a_0+a_1x+...+a_{\frac{n}{2}-1}x^{\frac{n}{2}-1}	\\
    A_1(x) = a_{\frac{n}{2}}+ a_{\frac{n}{2}+1}x+...+a_nx^{\frac{n}{2}}	\\
    A(x) = A_0(x)+A_1(x)x^{\frac{n}{2}}	\\
    Similarly, \ B(x) = B_0(x)+B_1(x)x^{\frac{n}{2}}	\\
    $$

  + äºæ˜¯ï¼Œ$A(x)B(x) = A_0(x)B_0(x) + A_0(x)B_1(x)x^{\frac{n}{2}}+A_1(x)B_0(x)x^{\frac{n}{2}}+A_1(x)B_1(x)x^n$

  + å¤æ‚åº¦è®¡ç®—ï¼š$T(n) = 4T(n/2)+n$ï¼›$Total = O(n^2)$

+ An improved divide-and-conquer algorithm

  + ä»¤ï¼š
    $$
    Y = (A_0+A_1)(B_0+B_1)	\\
    U = A_0B_0	\\
    Z = A_1B_1	\\
    A_0B_1+A_1B_0 = Y - U - Z
    $$

  + $Total = O(n^{log3})$

+ Analysis of the divide-and-conquer algorithm

  Fast Fourier Transformï¼ˆFFTï¼‰ç®—æ³•å¯è¾¾åˆ°ï¼š$O(nlogn)$

### å¿«é€Ÿæ’åºé—®é¢˜

Quicksort Problemï¼ˆå¿«é€Ÿæ’åºé—®é¢˜ï¼‰

+ Basic partition 
+ Randomized partition and randomized quicksort
+ Analysis of the randomized quicksort

## ç¬¬4+èŠ‚ å¿«é€Ÿæ’åºã€å †æ’åºã€åŸºäºæ¯”è¾ƒæ’åºçš„ä¸‹ç•Œ

Lecture 4+: Quicksort, Heapsort and Comparison-based Lower Bound for Sorting

### Introduction to Part II

ä¸‰ç§å‡ä¸º$O(n\log n)$

### Quicksort Problem

+ Basic partition 

+ Randomized partition and randomized quicksort

  ä¸ä¸Šé¢ç›¸æ¯”æ¯æ¬¡é€‰å–éšæœºä½ç½®åŸºå‡†æ•°ï¼Œæ‰€éœ€æ—¶é—´ä¸ä¾èµ–äºè¾“å…¥

+ Analysis of the randomized quicksort

  è®¡ç®—Expectionçš„p152é¡µæå…¶ç²¾å½©

### Heapsort Problem

+ Priority Queues

+ (Binary) Heap

  æ’å…¥ã€å–æœ€å°ï¼ˆæœ€å¤§ï¼‰å€¼å‡ä¸º$O(\log n)$

+ Heapsort

### åŸºäºæ¯”è¾ƒæ’åºçš„ä¸‹ç•Œ

Lower Bound for Comparison-based Sorting

+ Objective

  å¯è¯æ˜comparisionä¸‹çš„æ’åºæé™æ˜¯$O(n \log n)$ï¼Œè§p274

+ Decision Tree Model

## ç¬¬5èŠ‚ 0-1èƒŒåŒ…ä¸é’¢æ¡åˆ‡å‰²é—®é¢˜

Lecture 5: 0-1 Knapsack and Rod Cutting Problems

### 0-1èƒŒåŒ…é—®é¢˜

0-1 Knapsack Problemï¼ˆ0-1èƒŒåŒ…ï¼‰

#### é—®é¢˜å®šä¹‰

nä¸ªèƒŒåŒ…ï¼Œä»·å€¼åˆ†åˆ«$v_i$ï¼Œé‡é‡åˆ†åˆ«$w_i$ï¼Œé‡é‡ä¸è¶…è¿‡Wçš„æƒ…å†µä¸‹æ±‚æœ€å¤§ä»·å€¼ã€‚

#### A Bruteforce Algorithm

é€’æ¨å¼ï¼š
$$
V[i,w]=max(V[i-1,w], v_i+V[i-1,w-w_i])
$$
é€’å½’æ±‚è§£ï¼š
$$
KnapsackSR(i,w)=max\{ KnapsackSR(i-1,w), v_i + KnapsackSR(i-1,w-w_i) \}
$$
å¤æ‚åº¦ï¼š$\Omega(2^n)$

#### A Dynamic Programming Algorithm

æ ¸å¿ƒæ€æƒ³ï¼šè‡ªåº•å‘ä¸Šã€å¡«è¡¨

##### ä¼ªä»£ç 

![image-20220111090229955](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111090229955.png)

å¤æ‚åº¦ï¼š$O(nW)$

#### DPç®—æ³•åˆ†æ

### é’¢æ¡åˆ‡å‰²é—®é¢˜

Rod Cutting Problemï¼ˆé’¢æ¡åˆ‡å‰²é—®é¢˜ï¼‰

#### é—®é¢˜å®šä¹‰

ä¸€é’¢æ¡ï¼Œä¸åŒé•¿åº¦çš„ä»·å€¼$p_i$ç¡®å®šï¼Œåˆ‡å‰²æœ€å¤§ä»·å€¼ã€å¦‚ä½•åˆ‡å‰²æ€»ä»·å€¼æœ€å¤§ã€‚

#### A Bruteforce Algorithm

æš´åŠ›çš„é€’å½’ï¼š$r_n=max(p_n, r_1+r_{n-1}, r_2+r_{n-2}, ..., r_{n-1}+r_1)$

ç¨ç®€åŒ–ç‰ˆæœ¬ï¼š$r_n=\mathop{max}\limits_{1 \leq i \leq n} (p_i+r_{n-i})$

#### A Dynamic Programming Algorithm

è‡ªåº•å‘ä¸Šè®¡ç®—$r[n]$ï¼Œå¯¹æ¯ä¸€ä¸ª$j$ï¼Œiä»1åˆ°$j$éå†ï¼Œ$q \leftarrow max(q, p[i]+r[j-i])$ï¼Œå…±è®¡ç®—$j$æ¬¡

##### ä¼ªä»£ç 

![image-20220111090423653](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111090423653.png)

å¤æ‚åº¦ï¼š$O(n^2)$

## ç¬¬6èŠ‚ çŸ©é˜µé“¾ä¹˜æ³•å’Œæœ€é•¿å…¬å…±å­åºåˆ—

Lecture 6: Chain Matrix Multiplication and Longest Common Subsequence Problem

### çŸ©é˜µé“¾ä¹˜æ³•

Chain Matrix Multiplication Problemï¼ˆçŸ©é˜µé“¾ä¹˜æ³•ï¼‰

+ Review of Matrix Multiplication

  é—®é¢˜å®šä¹‰ï¼š$A_1A_2...A_n$çŸ©é˜µåºåˆ—ï¼Œæ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ä¹˜æ³•é¡ºåºï¼ˆåŠ æ‹¬å·ï¼‰ä½¿å¾—æ€»è¿ç®—æ•°æœ€å°

+ The Chain Matrix Multiplication Problem

+ A Dynamic Programming Algorithm

  é€’æ¨å…¬å¼ï¼š$m[i,j]= \mathop{min}\limits_{i \leq k < j}(m[i,k]+m[k+1,j]+p_{i-1}p_kp_j) $

  **å¤æ‚åº¦**ï¼š$O(n^3)$

### æœ€é•¿å…¬å…±å­åºåˆ—

Longest Common Subsequence Problemï¼ˆæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰

+ Longest Common Subsequence Problem
  $$
  d_{i,j}= \left\{ \begin{array}{rcl}
  d_{i-1,j-1}+1, & if \ x_i=y_j	\\
  max\{d_{i-1,j},d_{i,j-1}\}, & if \ x_i\neq y_j	\\
  \end{array}\right.
  $$

+ Longest Common Substring Problem
  $$
  d_{i,j}= \left\{ \begin{array}{rcl}
  d_{i-1,j-1}+1, & if \ x_i=y_j	\\
  0, & if \ x_i\neq y_j	\\
  \end{array}\right.
  $$
  
+ **å¤æ‚åº¦**ï¼šå‡ä¸º$O(n^2)$

## ç¬¬7èŠ‚ æœ€å°ç¼–è¾‘è·ç¦»é—®é¢˜

Lecture 7: Minimum Edit Distance Problem

### æœ€å°ç¼–è¾‘è·ç¦»

Minimum Edit Distance Problemï¼ˆæœ€å°ç¼–è¾‘è·ç¦»ï¼‰

#### åŠ¨æœºä¸åº”ç”¨

æ‹¼å†™æ£€æŸ¥ã€DNAç¼–è¾‘ã€æœºå™¨ç¿»è¯‘ç­‰

#### é—®é¢˜å®šä¹‰

Given two strings X=(x1, x2,â€¦, xm) and Y=(y1, y2,â€¦, yn), the edit distance is the smallest number of following edit operations to turn X into Y:

+ Insertion: add a letter
+ Deletion: remove a letter
+ Substitution: replace a character with another one.

#### The Dynamic Programming Algorithm

å°†$X[1...i]$è½¬å˜ä¸º$Y[1...j]$åˆ†ä¸‰ç§æƒ…å†µï¼š

+ Case 1: Turn $X[1...i-1]$è½¬å˜ä¸º$Y[1...j]$ å¹¶åˆ é™¤ $X[i]$

  Example 1 : MED (cxy-> dab) =MED (cx-> dab) + 1

+ Case 2: Turn $X[1...i]$è½¬å˜ä¸º$Y[1...j-1]$ å¹¶æ’å…¥ $Y[j]$

  Example 2: MED (cxy-> dab) = MED (cxy-> da) +1

+ Case 3: Turn $X[1...i-1]$è½¬å˜ä¸º$Y[1...j-1]$  and æ›¿æ¢ $X[i]$ with $Y[j]$ if needed (X[i]+YUij)

  Example 3.1 : MED (cxy-> dab) =MED (cx-> da) +1

  Example 3.2: MED (cxy-> day) =MED (cx-> da)D[i-1,j+1D[i,j]=minD[i,j-1]+1D[i-1,j-1] +10 if X[i] =Yj](1 otherwise.

åˆ™é€’æ¨å…¬å¼ä¸ºï¼š
$$
D[i.j]=min
\begin{cases}
D[i-1,j]+1 \\
D[i,j-1]+1 \\
D[i-1,j-1]+
\begin{cases}
0 & \text{if X[i]=Y[j]}\\
1 & \text{otherwise}
\end{cases}
\end{cases}
$$
ç”¨ä¸€ä¸ªè¾…åŠ©æ•°ç»„$p[i,j]$æ¥å­˜ä½ç½®

**å¤æ‚åº¦**ï¼š$O(mn)$

##### ä¼ªä»£ç 

![image-20220111090953805](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111090953805.png)

## ç¬¬9èŠ‚ åˆ†æ•°èƒŒåŒ…ã€æ´»åŠ¨é€‰æ‹©ä¸éœå¤«æ›¼ç¼–ç 

Lecture 9: Fraction Knapsack, Activity Selection and Huffman Coding Problems

### åˆ†æ•°èƒŒåŒ…é—®é¢˜

The Fractional Knapsack Problemï¼ˆåˆ†æ•°èƒŒåŒ…é—®é¢˜ï¼‰

+ Problem Definition

+ A Greedy Algorithm and correctness

  å…ˆ$O(n\log n)$æŒ‰ä»·å€¼æ’åºï¼Œä¹‹å$O(n)$æŒ‰ä»·å€¼é€‰ç‰©å“ï¼Œæœ€åè¯æ˜Correctness

### æ´»åŠ¨é€‰æ‹©é—®é¢˜

The Activity Selection Problemï¼ˆæ´»åŠ¨é€‰æ‹©é—®é¢˜ï¼‰

#### é—®é¢˜å®šä¹‰

#### è´ªå¿ƒç®—æ³•ä¸æ­£ç¡®æ€§

* è´ªå¿ƒçš„é€‰æ³•ï¼šé€‰æ‹©ç»“æŸæ—¶é—´æœ€æ—©çš„æ´»åŠ¨

* ç®—æ³•è¿‡ç¨‹ï¼šå…ˆ$O(n\log n)$æŒ‰ç»“æŸæ—¶é—´æ’åºï¼Œä¹‹åæœ€æ¯æ¬¡é€‰ç»“æŸæ—¶é—´æœ€æ—©çš„ï¼ˆå½“å‰ç¬¬ä¸€ä¸ªï¼‰ï¼Œå»é™¤å†²çªçš„æ´»åŠ¨ã€‚


##### è¯æ˜Correctness

åŸºæœ¬æ€æƒ³ï¼šWe can convert any other optimal solution(ğ‘ƒâ€²) to the greedy algorithm solution(ğ‘ƒ)

è¿‡ç¨‹ï¼š

* Compare the activities in ğ‘ƒâ€² and ğ‘ƒ from left to right
* If they match in the selected activity  â†’  skip
* If they do not match, we can replace the activity in ğ‘ƒâ€² by that in ğ‘ƒ because the one in ğ‘ƒ finish first

ä¾‹å¦‚ï¼Œåœ¨ä¸‹å›¾ä¸­ï¼Œè¯æ˜æœ€ä¼˜è§£å¯ä»¥â€œæ— æŸâ€è½¬åŒ–ä¸ºç®—æ³•è§£ï¼Œä¹‹å‰ã€ä¹‹åçš„æ—¶é—´å‡ä¸ä¼šå½±å“

![image-20211105161531971](ç®—æ³•è®¾è®¡ä¸åˆ†æ è¯¾ç¨‹ç¬”è®°.assets/image-20211105161531971.png)

#### Extended: Weighted Activity Selection

æ¯ä¸€é¡¹æ´»åŠ¨åŠ å…¥æƒé‡$w_i$ï¼Œæ‰¾æ€»æƒé‡å’Œæœ€å¤§çš„æ´»åŠ¨åºåˆ—

##### ç®—æ³•æ€æƒ³

* å®šä¹‰$p(j)$ ä¸ºæœ€å¤§çš„ç´¢å¼•$i$ä½¿å¾—æ´»åŠ¨$a_i$åœ¨ç¬¬$j$ä¸ªæ´»åŠ¨å‰ä¸”ä¸å†²çª

* åŠ¨æ€è§„åˆ’é€’æ¨å…³ç³»ï¼š
  $$
  OPT(j)=
  \begin{cases}
  0, &\text{if j=0}	\\
  max\{ OPT(j-1), w_j + OPT(p(j)) \}, &\text{if j>0}	\\
  \end{cases}
  $$

* ä¸€ä¸ªä¾‹å­

  ![image-20211105162615302](ç®—æ³•è®¾è®¡ä¸åˆ†æ è¯¾ç¨‹ç¬”è®°.assets/image-20211105162615302.png)

### éœå¤«æ›¼ç¼–ç é—®é¢˜

The Huffman Coding Problemï¼ˆéœå¤«æ›¼ç¼–ç é—®é¢˜ï¼‰

#### é—®é¢˜å®šä¹‰

* ä¸€ä¸ªæ£€æµ‹åç¼€çš„ç®—æ³•å¯ä»¥æ£€æµ‹æ˜¯å¦æ»¡è¶³å”¯ä¸€å¯è¯‘ï¼Œ1949å¹´

#### A Greedy Algorithm

è´ªå¿ƒæ€æƒ³ï¼šæ¯æ¬¡é€‰æœ€å°çš„xï¼Œyç»„æˆå­æ ‘ï¼Œæ›´æ–°æƒé‡ä¸ºx+y

#### æ­£ç¡®æ€§è¯æ˜

## ç¬¬9.xèŠ‚ ï¼Ÿï¼Ÿï¼Ÿ 

è¡¥å……äº†ä¸€éƒ¨åˆ†å…³äºé¦™å†œçš„ä¿¡æ¯ç†µç¼–ç å…¬å¼ã€Krash-McMilianå…¬å¼åŠè¯æ˜

### ä¿¡æ¯ç†µ

$$
H(X)=\sum_iP(x_i)I(x_i)=-\sum_iP(x_i)\log bP(x_i)
$$

åœ¨è¿™é‡Œbæ˜¯å¯¹æ•°æ‰€ä½¿ç”¨çš„åº•ï¼Œé€šå¸¸æ˜¯2,è‡ªç„¶å¸¸æ•°eï¼Œæˆ–æ˜¯10ã€‚å½“b = 2ï¼Œç†µçš„å•ä½æ˜¯bitï¼›

### Kraftâ€“McMillanå…¬å¼

è®¾ç¬¦å·è¡¨ä¸­çš„åŸå§‹ç¬¦å·ä¸º
$$
S=\{ s_1,s_2,...,s_n \}
$$
åœ¨å¤§å°ä¸º$r$çš„å­—ç¬¦é›†ä¸Šç¼–ç ä¸ºå”¯ä¸€å¯è§£ç¼–ç çš„ç å­—é•¿åº¦ä¸º
$$
l_1,l_2,...,l_n
$$
åˆ™
$$
\sum_{i=1}^n r^{-l_i} \leq 1
$$
åä¹‹ï¼Œç»™å®šä¸€ä¸ªæ»¡è¶³ä¸Šè¿°ä¸ç­‰å¼çš„è‡ªç„¶æ•°é›†åˆ$l_1,l_2,...,l_n$ , åˆ™åœ¨å¤§å°ä¸º$r$å­—ç¬¦é›†ä¸Šï¼Œå­˜åœ¨ä¸€ç»„å”¯ä¸€å¯è§£ç¼–ç ç¬¦åˆç›¸åº”çš„ç å­—é•¿åº¦ã€‚

## ç¬¬10èŠ‚ BFS/DFSã€æ‹“æ‰‘æ’åºä¸å¼ºè¿é€šåˆ†é‡

Lecture 10: Review of BFS/DFS, Topological Sort and Strongly Connected Components  

### å…³äºå›¾çš„æ¦‚å¿µ

### åŸºæœ¬å›¾æœç´¢ç®—æ³•

#### BFS

![image-20220111185029335](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185029335.png)

![image-20220111185008230](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185008230.png)

#### DFS

![image-20220111185101353](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185101353.png)

![image-20220111185111532](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185111532.png)

##### æ—¶é—´å¤æ‚åº¦

DFSVisitä¸­ï¼Œforå¾ªç¯æ‰§è¡Œäº† $Adj(u)=degree(u)$ æ¬¡

å¯¹æ¯ä¸ªé¡¶ç‚¹uï¼Œæ‰€éœ€æ—¶é—´ä¸º $T_u=O(1+degree(u))$

æ€»è¿è¡Œæ—¶é—´ä¸º
$$
\sum_{u\in V}T_u \leq \sum_{u\in V}O(1+degree(u)) = O(V+E)
$$
å› æ­¤ï¼Œæ—¶é—´å¤æ‚åº¦ $O(V+E)$

### æ‹“æ‰‘æ’åº

Topological Sort

#### ç®—æ³•æ€æƒ³

æ‹“æœ´æ’åºï¼šæ¯ä¸ªå…¥åº¦0åŠ è¿›å»ï¼Œåˆ é™¤

#### ä¼ªä»£ç 

![image-20220111185142433](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185142433.png)

#### å¤æ‚åº¦åˆ†æ

* å¤æ‚åº¦$O(V+E)$

æŒ‰DFSå®Œæˆæ—¶é—´çš„å€’åºæ’åˆ—

è€ƒè™‘ä¸¤é¡¶ç‚¹u -> v

* è‹¥vç°è‰²ï¼Œåˆ™vä¸ºuç¥–å…ˆï¼Œå½¢æˆç¯å›¾ï¼ŒçŸ›ç›¾ï¼
* è‹¥vç™½è‰²ï¼Œæ­£å¸¸è¾“å‡º
* è‹¥vé»‘è‰²

### å¼ºè¿é€šåˆ†é‡

#### æ¦‚å¿µ

è®¾$G= (V, E)$æ˜¯ä¸€ä¸ªæœ‰å‘å›¾ã€‚

Gçš„ä¸€ä¸ªå¼ºè¿é€šåˆ†é‡(SCC)æ˜¯Gçš„ä¸€ä¸ªå­é›†çš„Vä½¿å¾—ï¼š

å¯¹ä»»æ„ä¸¤ä¸ªé¡¶ç‚¹$u,v\in S$ï¼Œæ—¢æœ‰ä¸€æ¡u-vçš„è·¯å¾„ï¼Œä¹Ÿæœ‰ä¸€æ¡v-uçš„è·¯å¾„ã€‚

Sæ˜¯ä¸€ä¸ªæœ€å¤§é›†ï¼Œä¸èƒ½åœ¨ä¸è¿èƒŒä¸Šè¿°æ¡ä»¶çš„æƒ…å†µä¸‹å‘å…¶ä¸­åŠ å…¥æ›´å¤šçš„ç»“ç‚¹Våˆ°Sä¸­

#### æ±‚è§£SCCçš„ç®—æ³•

ç”¨åˆ°ä¸€ä¸ªåè½¬å›¾ $G^R$ çš„æ€æƒ³

ã€æ‘˜è‡ªwikiã€‘

1. å¯¹æœ‰å‘å›¾Gå–é€†ï¼Œå¾—åˆ°Gçš„åå‘å›¾ $G^R$
2. åˆ©ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢æ±‚å‡º $G^R$ çš„é€†åæ’åº
3. å¯¹GæŒ‰ç…§ä¸Šè¿°é€†åæ’åºçš„åºåˆ—è¿›è¡Œæ·±åº¦ä¼˜å…ˆæœç´¢
4. åŒä¸€ä¸ªæ·±åº¦ä¼˜å…ˆæœç´¢é€’å½’å­ç¨‹åºä¸­è®¿é—®çš„æ‰€æœ‰é¡¶ç‚¹éƒ½åœ¨åŒä¸€ä¸ªå¼ºè¿é€šåˆ†é‡å†…

#### ç®—æ³•è¿‡ç¨‹ Finding SCCs

* Step 1: Obtain the reverse graph GR by reversing the directions of all the edges in G.
* Step 2: Perform DFS on GR, and obtain the sequence LR that the vertices in GR turn black (i.e., whenever a vertex is popped out of the stack, append it to LR). Obtain L as the reverse order of LR.
* Step 3: Perform DFS on the original graph G by obeying the following rules:
  * Rule 1: Start the DFS at the first vertex of L.
  * Rule 2: Whenever a restart is needed, start from the first vertex of L that is still white.
    Output the vertices in each DFS-tree as an SCC.

![image-20220111185217231](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185217231.png)

#### å¤æ‚åº¦åˆ†æ

Steps 1 and 2 obviously require only ğ‘‚(|ğ‘‰|+|ğ¸|) time.

Regarding Step 3, the DFS itself takes ğ‘‚(|ğ‘‰|+|ğ¸|) time, but we still need to discuss the time to implement Rule 2. Namely, whenever DFS needs a restart, how do we find the first white vertex in L efficiently? This will be left as an exercise.

æ€»æ—¶é—´ä¸º $O(|V|+|E|)$. 

#### æ­£ç¡®æ€§è¯æ˜

ç¬¬ä¸€è½®å¯¹äºGRçš„DFSä¸­ï¼ŒS2ä¸­æœ€åä¸€ä¸ªé¡¶ç‚¹ç»“æŸæ—¶é—´ä¸€å®šä¼šæ™šäºS1çš„æœ€åä¸€ä¸ªé¡¶ç‚¹ç»“æŸæ—¶é—´ï¼Œè¿™æ ·åœ¨LRä¸­S2çš„æœ€åä¸€ä¸ªé¡¶ç‚¹æ¯”S1çš„æ›´é åï¼Œåœ¨Lä¸­æ›´é å‰ã€‚

## ç¬¬11èŠ‚ æœ€å°ç”Ÿæˆæ ‘

Lecture 11: Minimum Spanning Trees

### æœ€å°ç”Ÿæˆæ ‘

å®šä¹‰ã€æ¦‚å¿µç­‰

### Primâ€™s algorithm

#### æ ¸å¿ƒæ€æƒ³/ç®—æ³•å†…å®¹

æ­¥éª¤0:é€‰æ‹©ä»»æ„å…ƒç´ r;è®¾ç½®S=frå’ŒA=0ã€‚å°†rä½œä¸ºç”Ÿæˆæ ‘çš„æ ¹

æ­¥éª¤1:æ‰¾åˆ°ä¸€æ¡æœ€è½»çš„è¾¹ï¼Œä½¿ä¸€æ¡ç«¯ç‚¹åœ¨Sä¸­ï¼Œå¦ä¸€æ¡ç«¯ç‚¹åœ¨V\ sä¸­å°†è¿™æ¡è¾¹æ·»åŠ åˆ°aä¸­ï¼Œå°†å®ƒçš„(å…¶ä»–)ç«¯ç‚¹æ·»åŠ åˆ°Sä¸­ã€‚

æ­¥éª¤2å¦‚æœV\S=0ï¼Œåˆ™åœæ­¢ç”Ÿæˆæ ‘è¾“å‡º(æœ€å°)a;å¦åˆ™ï¼Œè¯·æ‰§è¡Œæ­¥éª¤1ã€‚

#### ä¼ªä»£ç 

![image-20220111185547194](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185547194.png)

#### å¤æ‚åº¦åˆ†æ

ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—PriQueueçš„æƒ…å†µä¸‹ï¼š

* å¯¹æ¯ä¸€ä¸ªVéœ€è¦$O(\log V)$çš„æ—¶é—´æŸ¥è¯¢æœ€å°çš„ï¼›
* å¯¹æ¯ä¸€ä¸ªEéœ€è¦$O(\log V)$çš„æ—¶é—´åœ¨ä¼˜å…ˆé˜Ÿåˆ—ä¸ŠDecrease-Keyï¼›

æ€»å¤æ‚åº¦ä¸ºï¼š
$$
O(V\log V+E\log V) = O((V+E)\log V)=O(E\log V)
$$

### Kruskalâ€™s algorithm

#### æ ¸å¿ƒæ€æƒ³

æ¯æ¬¡åŠ å…¥ä¸€æ¡æœ€å°çš„è¾¹ï¼Œä¸”ä¸ä¼šæˆç¯ï¼Œç›´åˆ°åŠ å…¥n-1æ¡è¾¹

#### å¹¶æŸ¥é›†

Union-Find supports three operations on collections of disjoint sets over some universe U. Let n = |U|. For any u,vâˆˆU:

* Create-Set(u): Create a set containing the single element u.
  $O(1)$ æ—¶é—´
* Find-Set(u): Find the set containing the element u. (Say each set has a unique ID)
  $O(\log n)$ æ—¶é—´
* Union(u, v): Merge the sets containing u and v respectively into a common set.
  $O(\log n)$ æ—¶é—´

è¿˜æœ‰ä¸€ç§æŒ‰ç…§heightè¿›è¡ŒUnionçš„ä¼˜åŒ–æ–¹å¼ï¼Œ

#### ä¼ªä»£ç 

![image-20220111185607842](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111185607842.png)

#### å¤æ‚åº¦åˆ†æ

........

## ç¬¬13èŠ‚ æœ€çŸ­è·¯é—®é¢˜

Lecture 13: Shortest Paths Problem

### å•æºæœ€çŸ­è·¯å¾„é—®é¢˜

ï¼ˆSingle-Source Shortest Paths Problemï¼‰

ç•¥

### Dijkstraâ€™s Algorithm

#### ä¸»ä½“æ€æƒ³

ç»´æŠ¤ä¸€äº›colorã€predã€å½“å‰æœ€çŸ­è·ç¦»dã€queueç­‰

* Dijå¤„ç†ä¸äº†è´Ÿæ•°æƒé‡

#### ä¼ªä»£ç 

![image-20220111190219402](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111190219402.png)

#### æ­£ç¡®æ€§è¯æ˜

5.3èŠ‚-p111

#### å¤æ‚åº¦åˆ†æ

* åˆå§‹åŒ–æ—¶é—´ O(|V|)ï¼›

* æ¯ä¸ªé¡¶ç‚¹åªè¢«å¤„ç†ä¸€æ¬¡ï¼Œæ‰€ä»¥Non-Empty()å’ŒExtract-Min()åªè¢«è°ƒç”¨ä¸€æ¬¡ï¼Œå³æ€»å…±O(|V|)æ¬¡ã€‚

* å¯¹äºå›¾ä¸­çš„æ¯æ¡è¾¹ï¼Œéƒ½è°ƒç”¨ä¸€æ¬¡for (each v E Adj[ul)çš„å†…éƒ¨å¾ªç¯ã€‚å†…éƒ¨å¾ªç¯çš„æ¯æ¬¡è°ƒç”¨éƒ½æ‰§è¡ŒO(1)æ“ä½œï¼Œå¯èƒ½è¿˜è¦åŠ ä¸Šä¸€ä¸ªDecrease-Keyæ“ä½œã€‚å›é¡¾æ‰€æœ‰ä¼˜å…ˆçº§é˜Ÿåˆ—æ“ä½œéœ€è¦O(log |Q|) = O(log|V|) æ—¶é—´ï¼›

* å› æ­¤ç®—æ³•æ€»å¤æ‚åº¦ä¸ºï¼š
  $$
  \begin{align}
  T(n)&= |V|\cdot O(\log|V|)+|E|\cdot O(1+\log |V||)\\
  &= O((|V|+|E|)\logâ¡|ğ‘‰| )\\
  &= O(|E|\log V)
  \end{align}
  $$

### The Bellman-Ford Algorithm

#### ç®—æ³•å†…å®¹

* å¾ªç¯$|V|-1$è½®ï¼Œæ¯ä¸€è½®ä¸­Relaxæ¯ä¸€æ¡è¾¹ï¼Œp132

#### åˆ†æ

* iç›¸å½“äºä»uåˆ°tçš„è·³æ•°ï¼Œè‹¥æ— ç¯æœ€å¤šV-1è·³å³å¯åˆ°
* å¯è¯æ˜è¯¥ç®—æ³•å°±æ˜¯in-placeåŸåœ°æ›´æ–°ç‰ˆæœ¬çš„DP

#### ä¼ªä»£ç 

![image-20220111190258267](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111190258267.png)

#### å¤æ‚åº¦

$O(|V|\cdot |E|)$

#### ä¸€ä¸ªæœ‰è¶£çš„å®é™…åº”ç”¨

* è´§å¸æ±‡ç‡å…‘æ¢ï¼Œæœ‰æ— å¯èƒ½ä¸€åœˆä¸‹æ¥ä¹˜ç§¯>1å³é’±å˜å¤šäº†ï¼šç­‰ä»·äº->æ¯æ¡è¾¹å–logçœ‹æ˜¯å¦æœ‰è´Ÿç¯

### ä»»æ„ä¸¤ç‚¹æœ€çŸ­è·¯é—®é¢˜

The All-pairs Shortest Path Problem

#### é—®é¢˜å®šä¹‰

#### The Floyd-Warshall Algorithm

* $d_{ij}^{(k)}$ä¸­çš„ä¸Šæ ‡kæŒ‡å¯ç”¨å‰kä¸ªå·çš„èŠ‚ç‚¹ï¼Œè€Œä¸è·³æ•°æ— å…³ï¼

##### ä¸»è¦æ€æƒ³

For a shortest path from i to j with intermediate vertices from the set {1,2,â€¦,k}, there are two possibilities:
k is not a vertex on the path: ğ‘‘_ğ‘–ğ‘—^((ğ‘˜) )=ğ‘‘_ğ‘–ğ‘—^((ğ‘˜âˆ’1) )
k is a vertex on the path:ğ‘‘_ğ‘–ğ‘—^((ğ‘˜) )=ğ‘‘_ğ‘–ğ‘˜^((ğ‘˜âˆ’1) )+ğ‘‘_ğ‘˜ğ‘—^((ğ‘˜âˆ’1) )
So:
ğ‘‘_ğ‘–ğ‘—^((ğ‘˜) )=minâ¡{ğ‘‘_ğ‘–ğ‘—^((ğ‘˜âˆ’1) ),ğ‘‘_ğ‘–ğ‘˜^((ğ‘˜âˆ’1) )+ğ‘‘_ğ‘˜ğ‘—^((ğ‘˜âˆ’1) )}

##### ä¼ªä»£ç 

Floyd-Warshallï¼ˆwï¼Œnï¼‰

![image-20220111081343998](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111081343998.png)

##### å¤æ‚åº¦

æ—¶é—´å¤§å°$\Theta(n^3)$ï¼Œç©ºé—´ä¹Ÿä¸º $O(n^3)$ ï¼Œä½†é‡‡ç”¨å°±åœ°æ›´æ–°in-placeå¯å‡å°åˆ°O(x^2)

## ç¬¬14èŠ‚ æœ€å¤§æµ

ï¼ˆLecture 14: Maximum Flow ï¼‰

### æœ€å¤§æµ/æœ€å°å‰²é—®é¢˜

Maximum Flow Minimum Cut Problem

#### é—®é¢˜å®šä¹‰

##### æœ€å°å‰²

A st-cut (cut) ï¼ˆæœ€å°å‰²ï¼‰æ˜¯ä¸€ä¸ªåˆ†å‰²ï¼ˆA,Bï¼‰ä½¿å¾— $s\in A$ ï¼Œ$t\in B$

å®ƒçš„å®¹é‡ç­‰äºä»Aåˆ°Bçš„è¾¹çš„å®¹é‡ä¹‹å’Œã€‚
$$
cap(A,B) = \sum_{\text{e out of A}}c(e)
$$
##### æµé›†st-flow

å®šä¹‰ï¼šAn st-flow(flow)ï¼ˆæµé›†ï¼‰fæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæ»¡è¶³ï¼š

* å¯¹æ¯ä¸ª $e\in E$ï¼Œ$0\leq f(e) \leq c(e)$
* å¯¹æ¯ä¸ª $v\in V-\{ s,t \}$ ï¼Œ$\sum_{e\ into\ v}f(e) = \sum_{e\ out\ of\ v}f(e)$

æµé›†fçš„valueä¸ºï¼š
$$
val(f)=\sum_{e\ out\ of\ v}f(e)
$$

### Heuristic Algorithm

* æ‰¾æ‰€æœ‰såˆ°tçš„è·¯å¾„ï¼Œå¹¶è´ªå¿ƒåœ°å¡«å……å…¨éƒ¨è¾¹ï¼Œç›´åˆ°stuckä½
* ä½†å¾—å‡ºçš„ä¸ä¸€å®šæ˜¯æœ€ä¼˜è§£

### Ford-Fulkerson Method

#### å¼•å…¥æ¦‚å¿µ

##### æ®‹å­˜å›¾ï¼ˆResidual Graphï¼‰

æ®‹å­˜è¾¹çš„å®šä¹‰ï¼š
$$
c_f(e)=
\begin{cases}
c(e)-f(e), & if \ e \in E	\\
f(e), & if\ e^R \in E
\end{cases}
$$
ç¤ºæ„å›¾ï¼š

![image-20211217162659766](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20211217162659766.png)

æ®‹å­˜è¾¹æ„æˆæ®‹å­˜å›¾$G_f=(V,E_f)$

##### å¢å¹¿è·¯å¾„ï¼ˆAugmenting Pathï¼‰

å®šä¹‰ï¼šä¸€æ¡åœ¨å‰©ä½™å›¾$G_f$ä¸­såˆ°tçš„è·¯å¾„

##### ç“¶é¢ˆå®¹é‡ï¼ˆbottleneck capacityï¼‰

å®šä¹‰ï¼šbottleneck capacity of an augmenting ğ‘ƒ is the minimum residual capacity of any edge in ğ‘ƒ.

##### ä¸€ä¸ªå®šç†ï¼Ÿ

ä»¤fæ˜¯ä¸€ä¸ªæµï¼ˆflowï¼‰ï¼ŒPæ˜¯ä¸€æ¡Gä¸­çš„å¢å¹¿è·¯å¾„ï¼Œåˆ™$f^{'}$æ˜¯ä¸€ä¸ªæ–°çš„æµä¸”æœ‰
$$
val(f^{'})=val(f)+bottleneck(G_f,P)
$$
#### ä¸»è¦æ€æƒ³

1. Start with ğ‘“(ğ‘’)=0 for all edge $e\in E$.
2. Find an augmenting path ğ‘ƒ in the residual graph $ğº_ğ‘“$.
3. Augment flow along path ğ‘ƒ.
4. Repeat until you get stuck.

#### ä¼ªä»£ç 

![image-20220111193921254](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20220111193921254.png)

![image-20211217142751696](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20211217142751696.png)

#### å®ä¾‹åˆ†æ

è‡³p70

#### å¤æ‚åº¦åˆ†æ

æ¯æ¬¡åœ¨residual graphä¸­æ‰¾è·¯å¾„ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºï¼š$O(V+2E)=O(E)$ 

æ€»å¤æ‚åº¦ $ğ‘‚(E\cdot |ğ‘“^*|)$ï¼ˆå…¶ä¸­f*æ˜¯æœ€å¤§æµçš„å€¼ï¼‰

ä¸€äº›é€‰æ‹©aug pathçš„å¥½æ–¹æ³•ï¼šEdmonds-Karp ç®—æ³•æ¯æ¬¡è¿­ä»£é€‰æ‹©è·³æ•°æœ€å°‘çš„å¢å¹¿è·¯å¾„ã€‚å¯ä»¥è¯æ˜ï¼Œè¿™æ ·é€‰å–çš„å¢å¹¿è·¯å¾„çš„è·³æ•°å•è°ƒé€’å¢ï¼Œä¸”æ¯æ¡è¾¹æˆ–åå‘è¾¹æˆä¸º bottleneck edge æœ€å¤š n/2 æ¬¡ã€‚å› æ­¤ï¼ŒEdmonds-Karp ç®—æ³•çš„è¿è¡Œæ—¶é—´ä¸º O(m2n)ã€‚

##### ä¸€ä¸ªæç«¯çš„ä¾‹å­

éœ€è¦æ“ä½œ100wæ¬¡ï¼p75

![image-20211217172322860](ç®—æ³•è®¾è®¡ä¸åˆ†æ ç¬”è®°.assets/image-20211217172322860.png)

### æœ€å¤§æµ/æœ€å°å‰²å®šç†

Maximum-Flow Minimum-Cut Theorem

è¯æ˜ä¸ºä»€ä¹ˆè¯¥ç®—æ³•æ­£ç¡®

#### æµå€¼å¼•ç† Flow value lemma

Let ğ‘“ be any flow and let (ğ´,ğµ) be any cut. Then, the net flow across (ğ´,ğµ) equals the value of ğ‘“.
$$
\sum_\text{e out of A} f(e)-\sum_\text{e in to A} f(e)=val(f)
$$
è¯æ˜p86

#### å¼±å¯¹å¶å®šç† Weak Duality

Weak duality. Let ğ‘“ be any flow and (ğ´,ğµ) be any cut. Then, ğ‘£ğ‘ğ‘™(ğ‘“) â‰¤ ğ‘ğ‘ğ‘(ğ´, ğµ).

#### å¢å¹¿è·¯å¾„å®šç† Augmenting path theorem

A flow f is a max-flow iff no augmenting paths.

#### æœ€å¤§æµ-æœ€å°å‰²ç­‰ä»· Max-flow min-cut theorem

 Value of the max-flow = capacity of min-cut.

å¼±å¯¹å¶å®šç†çš„åŠ å¼ºç‰ˆ

#### ä¸‰ä¸ªç­‰ä»·å™è¿°

è¯æ˜ä»¥ä¸‹ä¸‰ä¸ªæè¿°ç­‰ä»·

ğ‘“:
ğ‘–. There exists a cut (ğ´,ğµ) such that ğ‘ğ‘ğ‘(ğ´,ğµ) = ğ‘£ğ‘ğ‘™(ğ‘“).
ğ‘–ğ‘–. ğ‘“ is a max-flow.
ğ‘–ğ‘–ğ‘–. There is no augmenting path with respect to ğ‘“.

p96-98å¾ªç¯è¯æ˜ï¼Œåˆ©ç”¨åˆ°äº†å¼±å¯¹å¶å®šç†

## ç¬¬13èŠ‚ Pã€NPã€NPCé—®é¢˜

ï¼ˆLecture 13: Problem Classes: P, NP, NP-Completenessï¼‰

### Pä¸NPé—®é¢˜

* è¯•å›¾è¯æ˜æ˜¯NPå®Œå…¨é—®é¢˜ï¼Œåˆ™æ— å¤šé¡¹å¼ç®—æ³•

#### é—®é¢˜çš„Input size

* å…ˆè§„èŒƒåŒ–input size

äºŒè¿›åˆ¶bitä½çš„ç»Ÿä¸€

same typeçš„å®šä¹‰

è®¤ä¸ºå¤šé¡¹å¼å¥—åˆ°å¦ä¸€ä¸ªå¤šé¡¹å¼é‡Œä»ä¸ºå¤šé¡¹å¼
$$
c_1g(n^{a_1})^{b_1} \leq f(n) \leq c_2g(n^{a_2})^{b_2}
$$


#### Optimization problems vs Decision problems

##### åˆ¤å®šé—®é¢˜

* å›ç­”yesæˆ–noçš„ä¸€ç±»é—®é¢˜
* å¦‚æœLæ˜¯é—®é¢˜ï¼Œxæ˜¯è¾“å…¥ï¼Œæˆ‘ä»¬ç»å¸¸å†™xâˆˆLè¡¨ç¤ºæ˜¯yesç­”æ¡ˆï¼ŒxâˆˆLè¡¨ç¤ºnoç­”æ¡ˆã€‚ 

##### ä¼˜åŒ–é—®é¢˜

* ä¸€ä¸ªä¼˜åŒ–é—®é¢˜çš„ç­”æ¡ˆéœ€è¦æ˜¯ä¸€ä¸ªæœ€ä¼˜è§£
* ä¸€ä¸ªä¼˜åŒ–é—®é¢˜é€šå¸¸æœ‰ä¸€ä¸ªç›¸åº”çš„å†³ç­–é—®é¢˜ï¼ˆå¦‚äºŒåˆ†ã€æŠ˜åŠæŸ¥æ‰¾ä»¥æ­¤è¯¢é—®yesæˆ–noï¼Œä»è€Œåˆ¤å®šå‡ºæœ€ä¼˜ï¼ŒäºŒè€…æˆ–è®¸æ˜¯å¯¹åº”ä¸€ä¸ªå¤šé¡¹å¼æ—¶é—´çš„ç³»æ•°ï¼‰
* ä¾‹å¦‚ï¼šMST vs. Decision Spanning Tree (DST)ã€Knapsack vs. Decision Knapsack (DKnapsack)

#### Pä¸NPé—®é¢˜

ï¼ˆæ ¸å¿ƒï¼‰

##### Pç±»é—®é¢˜

èƒ½å¤Ÿåœ¨å¤šé¡¹å¼æ—¶é—´å†…è§£å†³

##### yesä¸no inputçš„æ¦‚å¿µ

##### certificateçš„å®šä¹‰

ä¸€ä¸ªå¯ä»¥åˆ¤æ–­æ˜¯yes-inputçš„è¯æ®

##### NPç±»é—®é¢˜

NPç±»åŒ…å«äº†æ‰€æœ‰çš„å†³ç­–é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œå¯¹äºæ¯ä¸€ä¸ªâ€œæ˜¯â€è¾“å…¥ï¼Œéƒ½å­˜åœ¨ä¸€ä¸ªè¯æ®ï¼Œå®ƒå…è®¸äººä»¬åœ¨å¤šé¡¹å¼æ—¶é—´å†…éªŒè¯è¾“å…¥ç¡®å®æ˜¯ä¸€ä¸ªâ€œæ˜¯â€è¾“å…¥ã€‚

ä¸€äº›è‘—åçš„NPé—®é¢˜ï¼š
$$
DVC\in NP, k-SAT\in NP
$$
å¦ä¸€ä¸ªå­˜ç–‘çš„ä¸–çºªéš¾é¢˜
$$
P=NP?
$$

* æ˜¯æ— æ³•åˆ¤æ–­æ­£è¯¯çš„ï¼Œç›®å‰åªçŸ¥é“$P\subseteq NP$ï¼Œå¦ä¸€ä¸ªæ–¹å‘æ— æ³•åˆ¤æ–­

### NPCé—®é¢˜

ï¼ˆæ ¸å¿ƒï¼Œå…³äºNP-Completenessï¼‰

#### Polynomial-time reductions

##### å½’çº¦ï¼ˆReductionï¼‰

* å½’çº¦æ˜¯é—®é¢˜ä¹‹é—´çš„å…³ç³»ã€‚

* å¦‚æœQçš„æ¯ä¸ªå®ä¾‹éƒ½å¯ä»¥è¢«â€œé‡æ–°è¡¨è¾¾â€ä¸ºQçš„ä¸€ä¸ªå®ä¾‹ï¼Œé‚£ä¹ˆé—®é¢˜Qå¯ä»¥ç®€åŒ–ä¸ºQ'ã€‚ä¸€ä¾‹å¦‚ä¸‹ï¼š

  * Q:ä¸¤ä¸ªæ­£æ•°ç›¸ä¹˜ã€‚

  * Q':ä¸¤ä¸ªæ•°ç›¸åŠ ã€‚

  * Qå¯ä»¥é€šè¿‡ä¸€ä¸ªå¯¹æ•°å˜æ¢è¢«ç®€åŒ–ä¸ºQ'
    $$
    xy = exp[logx +logy]
    $$

* å¦‚æœQå¯ä»¥è¢«ç®€åŒ–ä¸ºQ'ã€‚Qå¹¶ä¸æ¯”Q'æ›´éš¾è§£ã€‚

##### å¤šé¡¹å¼æ—¶é—´å½’çº¦ï¼ˆPolynomial-Time Reductionsï¼‰

ä¸€ä¸ªPoly-Tå½’çº¦æŒ‡çš„æ˜¯ä¸€ä¸ªä»$L_1$åˆ°$L_2$çš„æ˜ å°„fï¼ŒL1ä¸­çš„yes-inputä»å¯¹åº”åˆ°L2ä¸­çš„yes-inputï¼Œno-inputåŒç†ã€‚å¦‚æœè¿™æ ·çš„æ˜ å°„få­˜åœ¨ï¼Œåˆ™ç§°$L_1$èƒ½å¤Ÿå¤šé¡¹å¼å½’çº¦åˆ°$L_2$ï¼Œè®°ä½œï¼š
$$
L_1 \leq_P L_2
$$
ä¸€äº›æ€§è´¨ï¼š

* $L_1 \leq_P L_2$æ„å‘³ç€$L_1$ä¸ä¼šæ¯”$L_2$æ›´éš¾ï¼›
* ç»™å®šä¸€ä¸ªç®—æ³•$A_2$è§£é—®é¢˜$L_2$ï¼Œåˆ™èƒ½å¤Ÿç”±æ­¤æ„é€ å‡ºä¸€ä¸ªè§£å†³é—®é¢˜$L_1$çš„ç®—æ³•$A_1$ï¼ˆä¸”å¯ä¿æŒå¤šé¡¹å¼æ€§è´¨ï¼‰

##### å…¶ä½™æ€§è´¨

ã€Pç±»é—®é¢˜ã€‘

è‹¥$L_1 \leq_P L_2$ä¸”æœ‰$\ L_2\in P$ï¼Œåˆ™$L_1\in P$

ã€ä¼ é€’æ€§ã€‘

è‹¥$L_1 \leq_P L_2$ä¸”$L_2 \leq_P L_3$ï¼Œåˆ™$L_1 \leq_P L_3$

#### The class NPC

##### NPCé—®é¢˜å®šä¹‰

NPCç±»é—®é¢˜Læ»¡è¶³ä¸¤ä¸ªæ€§è´¨ï¼š

1. $L\in NP$ï¼›
2. å¯¹ä»»æ„$L^{'}\in NP$ï¼Œ$L^{'} \leq_P L$

* NPCé—®é¢˜åŒ…å«äº†å…¨éƒ¨NPé—®é¢˜ä¸­çš„æœ€éš¾é—®é¢˜

##### NPCç›¸å…³å®šç†

Læ˜¯ä¸€ä¸ªNPCé—®é¢˜ï¼ˆp62ï¼‰

* å¦‚æœå­˜åœ¨å¯¹Lçš„å¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼Œåˆ™æ¯ä¸ª$L^{'}\in NP$éƒ½æœ‰ä¸€ä¸ªå¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼›
* å¦‚æœä¸å­˜åœ¨Lçš„å¤šé¡¹å¼æ—¶é—´ç®—æ³•ï¼Œåˆ™ä»»ä½•$L^{'}\in NPC$éƒ½æ²¡æœ‰å¤šé¡¹å¼æ—¶é—´ç®—æ³•ã€‚

#### NP-Complete problems

##### Cookå®šç†

$$
SAT\in NPC
$$

ä¸€ä¸ªè¶³çŸ£è·å¾—å›¾çµå¥–çš„ç®€å•å…¬å¼

##### NPCé—®é¢˜èŒƒç•´

ç»å…¸NPCé—®é¢˜ï¼šSAT and 3-SATã€DCLIQUEã€Decision Vertex Cover (DVC)ã€Decision Independent Set (DIS)

* cliqueé—®é¢˜ï¼šæ‰¾æ— å‘å›¾Gçš„å®Œå…¨å­å›¾

ç»™å‡ºäº†ä¸€ç§3-SATåˆ°cliqueçš„æ„é€ ä¸ç­‰ä»·æ€§åˆ¤å®š

* Independent Setç‹¬ç«‹é›†é—®é¢˜ï¼šæ‰¾é¡¶ç‚¹å­é›†ï¼Œåœ¨åŸå›¾ä¸Šä»»æ„2ç‚¹æ— è¾¹ç›´æ¥ç›¸è¿ã€‚æ‰¾åˆ°æœ€å¤§çš„æ»¡è¶³è¯¥é—®é¢˜çš„é›†åˆå¤§å°

ç”¨ $DCLIQUE\leq_P DIS$ çš„å½’çº¦è¯æ˜æ–¹å¼

* Vertex Coveré¡¶ç‚¹è¦†ç›–é—®é¢˜ï¼šä¸€äº›é¡¶ç‚¹é›†åˆï¼Œè¦†ç›–äº†Gä¸­æ¯æ¡è¾¹ï¼ˆä»»ä½•ä¸€æ¡è¾¹è‡³å°‘æœ‰ä¸€ä¸ªç«¯ç‚¹åœ¨é›†åˆä¸­ï¼‰ã€‚æ‰¾æœ€å°çš„vertex cover

å¯è¯æ˜è‹¥ä¸€ä¸ªVC=Uï¼Œåˆ™Uçš„è¡¥é›†æ˜¯ä¸€ä¸ªç‹¬ç«‹é›†DISã€‚è¯æ˜ï¼š1. è‹¥ä¸æ˜¯DISï¼Œåˆ™è¡¥é›†æœ‰2è¾¹ç›¸è¿ï¼Œåˆ™VCæœªè¦†ç›–allï¼›åä¹‹...

pptä¸­è¯æ˜ä¸DCLIQUEç­‰ä»·ç•¥éº»çƒ¦

#### NPCä¸­çš„åˆ¤å®šä¸ä¼˜åŒ–é—®é¢˜

NP-Hardé—®é¢˜

ä¸€ä¸ªNPCé—®é¢˜å¯ä»¥å½’çº¦åˆ°æœ¬é—®é¢˜ã€‚

* ä¸ä¸€å®šæ˜¯NPé—®é¢˜ï¼›
* ä¸ä¸€å®šæ˜¯decisioné—®é¢˜ï¼Œå¯ä¸ºä¼˜åŒ–é—®é¢˜

### æ€»ç»“

è€ƒè¯•èŒƒå›´å†…ï¼š

Input size of problems.
Polynomial-time and nonpolynomial-time algorithms.
Polynomial-time solvable problems.
Decision problems.
Optimization problems and their decision problems.
The classes P, NP, and NPC.
Polynomial-time reduction.
How to prove L âˆˆ P, or NP, or NPC?
Examples of problems in these classes.

Satisfiability of Boolean formulas (SAT)
Decision clique (DCLIQUE)
Decision vertex cover (DVC)
Decision independent set (DIS)

## ç¬¬14èŠ‚ è¿‘ä¼¼ç®—æ³•

ï¼ˆLecture 14: Approximation Algorithmsï¼‰

### ç®€ä»‹

è¿‘ä¼¼ç®—æ³•ï¼šæ‰¾åˆ°ä¸€ä¸ªnear-optimalçš„è§£

#### è¿‘ä¼¼æ¯”ç‡

ä»¤Cä¸ºçš„è¿‘ä¼¼ç®—æ³•çš„costï¼ŒC*æ˜¯æœ€ä¼˜ç®—æ³•çš„costã€‚å®šä¹‰approximation ratio $\rho(n)$ï¼š
$$
max(\frac{C}{C^*},\frac{C^*}{C})\leq \rho(n)
$$
ä¸€äº›æ€§è´¨ï¼š

* ä¸€èˆ¬å†™ä½œ$\rho$æˆ– $1+\epsilon$
* $\epsilon$ å¯ä¸ºå¸¸æ•°æˆ–ä¸nç›¸å…³

### Vertex-Cover é—®é¢˜

#### è´ªå¿ƒæƒ³æ³•

ä¸€ç§è´ªå¿ƒçš„é€‰åº¦æœ€å¤šçš„ç‚¹ä¸ºSetä¸­å…ƒç´ ï¼Œæœ‰åæƒ…å†µp13ï¼Œæ‰©å±•æ„é€ æƒ…å†µp16

æœ€ä¼˜è§£ $OPT=k!$ï¼Œ æœ€åæƒ…å†µ $SOL=k!\log(k)$ï¼Œ æ­¤æ—¶ $\rho(n)=\log(k)$

#### Matchingç®—æ³•

åŒ¹é…ï¼ˆMatchingï¼‰ï¼šä¸€äº›è¾¹çš„é›†åˆMï¼Œæ¯ä¸ªç‚¹æœ€å¤šåœ¨Mä¸­å‡ºç°ä¸€æ¬¡

åœ¨ä¸€ä¸ªäºŒéƒ¨å›¾ï¼ˆäºŒåˆ†å›¾ï¼Œbipartiteï¼‰ä¸­ï¼Œä¸€ä¸ªç»“è®ºï¼šmaximum matching = minimum vertex cover

æ‰¾æ‰€æœ‰æå¤§Mathingï¼Œè¾“å‡ºæ‰€æœ‰è¾¹ä¸¤è¾¹ç«¯ç‚¹ï¼Œå³ä¸ºVCçš„è§£

SOL <= 2 * size of a maximum matching

å…¶ $\rho(n)=2$ ï¼Œå·²ç»æ˜¯ç›®å‰ä¸–ç•Œæœ€å¥½çš„è¿‘ä¼¼ç®—æ³•äº†

### Set-Cover é—®é¢˜

ç•¥

### Traveling-Salesman Problem

ç•¥

## æœŸæœ«å¤ä¹ 

* ==**ä¸€å®š**==çœ‹ä¸€éä¾‹é¢˜

* è¿‘ä¼¼ç®—æ³• Falseï¼Œä¸è€ƒ

* é€‰æ‹©å¡«ç©ºé¢˜ï¼ŒæŒ‡å®šä¸ªæ•°
* åˆ¤æ–­é¢˜ã€‚çœ‹é¢˜é¢æ˜¯å¦è¦ç»™â€œè¯´æ˜
* å®ä¾‹è¿è¡Œï¼Œå¯èƒ½ç»™ä¸ªæ•°ç»„ï¼Ÿ

### åŸºç¡€çŸ¥è¯†

### åˆ†æ²»ç®—æ³•(Divide and Conquer)

åˆ†è€Œæ²»ä¹‹çš„é—®é¢˜å®ä¾‹

* MergeSort  (å½’å¹¶æ’åº)
* Maximum Contiguous Subarray (æœ€å¤§å­æ•°ç»„)
* Counting Inversions (é€†åºè®¡æ•°)
* Polynomial Multiplication (å¤šé¡¹å¼ä¹˜æ³•)
* QuickSort and Partition (å¿«é€Ÿæ’åºä¸åˆ’åˆ†)
* Randomized Selection (éšæœºé€‰æ‹©)
* Lower Bound for Sorting (åŸºäºæ¯”è¾ƒçš„æ’åºä¸‹ç•Œ)

### åŠ¨æ€è§„åˆ’(Dynamic Programming)

åŠ¨æ€è§„åˆ’çš„é—®é¢˜å®ä¾‹

* 0-1 Knapsack (0-1èƒŒåŒ…)
* Maximum Contiguous Subarray (æœ€å¤§å­æ•°ç»„)
* Longest Common Subsequences (æœ€é•¿å…¬å…±å­åºåˆ—)
* Longest Common Substrings (æœ€é•¿å…¬å…±å­ä¸²)
* Minimum Edit Distance (æœ€å°ç¼–è¾‘è·ç¦»)
* Rod-Cutting (é’¢æ¡åˆ‡å‰²)
* Chain Matrix Multiplication (çŸ©é˜µé“¾ä¹˜æ³•)

### è´ªå¿ƒç®—æ³•(Greedy Algorithms)

æå‡ºè´ªå¿ƒç­–ç•¥ï¼šè§‚å¯Ÿé—®é¢˜ç‰¹å¾ï¼Œæ„é€ è´ªå¿ƒé€‰æ‹©

è¯æ˜ç­–ç•¥æ­£ç¡®ï¼šå‡è®¾æœ€ä¼˜æ–¹æ¡ˆï¼Œé€šè¿‡æ›¿æ¢è¯æ˜

è´ªå¿ƒç®—æ³•çš„é—®é¢˜å®ä¾‹

* Fractional Knapsack (éƒ¨åˆ†èƒŒåŒ…)
* Huffman Coding (éœå¤«æ›¼ç¼–ç )
* Activity Selection (æ´»åŠ¨é€‰æ‹©)
* Minimum Spanning Trees (æœ€å°ç”Ÿæˆæ ‘)
* Single-Source Shortest Paths (å•æºæœ€çŸ­è·¯å¾„)

### å›¾ç®—æ³•(Graph Algorithms)

#### å„ç§é—®é¢˜

* Basic Concepts of Graphs (å›¾çš„åŸºæœ¬æ¦‚å¿µ)
* Breadth-First Search [BFS] (å¹¿åº¦ä¼˜å…ˆæœç´¢)
* Depth-First Search [DFS] (æ·±åº¦ä¼˜å…ˆæœç´¢)
* Cycle Detectionï¼ˆç¯è·¯æ£€æµ‹ï¼‰
* Topological Sort (æ‹“æ‰‘æ’åº)
* Strongly Connected Components (å¼ºè”é€šåˆ†é‡)
* Minimum Spanning Trees (æœ€å°ç”Ÿæˆæ ‘)
  * Primâ€™s Algorithm
  * Kruskalâ€™s algorithm
* Single-Source Shortest Paths (å•æºæœ€çŸ­è·¯å¾„)
  * Dijkstra Algorithm 
  * Bellman-Ford Algorithm

#### å›¾çš„æ¦‚å¿µä¸è¡¨ç¤º

* å›¾çš„å®šä¹‰ã€ç›¸é‚»ä¸å…³è”
* é¡¶ç‚¹çš„åº¦ä¸å›¾çš„åº¦ã€æ¡æ‰‹å®šç†
* è·¯å¾„ä¸ç¯è·¯
* è¿é€šã€è¿é€šåˆ†é‡
* å­å›¾ã€ç”Ÿæˆå­å›¾ã€æ ‘
* é‚»æ¥é“¾è¡¨ä¸é‚»æ¥çŸ©é˜µ

#### å›¾çš„æœç´¢ç®—æ³•

BFSï¼šæ— æƒå›¾çš„æœ€çŸ­è·¯å¾„ã€æ‹“æ‰‘æ’åº

DFSï¼šå¼ºè¿é€šåˆ†é‡ã€ç¯è·¯çš„å­˜åœ¨æ€§åˆ¤æ–­ã€æ‹“æ‰‘æ’åº

#### æœ€å°ç”Ÿæˆæ ‘

è´ªå¿ƒç®—æ³•åº”ç”¨

| **é€šç”¨æ¡†æ¶** | **Prim**ç®—æ³•             | **Kruskal**ç®—æ³•            |
| ------------ | ------------------------ | -------------------------- |
| æˆç¯åˆ¤æ–­     | å§‹ç»ˆä¿æŒä¸€æ£µæ ‘ï¼Œä¸æ–­æ‰©å±• | æ£®æ—åˆæˆä¸€æ£µæ ‘ï¼Œä¸ç›¸äº¤é›†åˆ |
| è½»è¾¹å‘ç°     | ä¼˜å…ˆé˜Ÿåˆ—                 | å…¨éƒ¨è¾¹æ’åº                 |
| æ±‚è§£è§†è§’     | å¾®è§‚è§†è§’ï¼ŒåŸºäºå½“å‰ç‚¹é€‰è¾¹ | å®è§‚è§†è§’ï¼ŒåŸºäºå…¨å±€é¡ºåºé€‰è¾¹ |
| ç®—æ³•æ€æƒ³     | éƒ½æ˜¯é‡‡ç”¨è´ªå¿ƒç­–ç•¥çš„å›¾ç®—æ³• | éƒ½æ˜¯é‡‡ç”¨è´ªå¿ƒç­–ç•¥çš„å›¾ç®—æ³•   |

#### å•æºæœ€çŸ­è·¯å¾„

è´ªå¿ƒç®—æ³•åº”ç”¨

|          | å¹¿åº¦ä¼˜å…ˆæœç´¢ | **Dijkstra**ç®—æ³•       | **Bellman-Ford**ç®—æ³• |
| -------- | ------------ | ---------------------- | -------------------- |
| é€‚ç”¨èŒƒå›´ | æ— æƒå›¾       | å¸¦æƒå›¾ï¼ˆæ‰€æœ‰è¾¹æƒä¸ºæ­£ï¼‰ | å¸¦æƒå›¾               |
| æ¾å¼›æ¬¡æ•° | --           | $|E|$ æ¬¡               | $|V|\cdot |E|$ æ¬¡    |
| æ•°æ®ç»“æ„ | é˜Ÿåˆ—         | ä¼˜å…ˆé˜Ÿåˆ—               | --                   |
| è¿è¡Œæ—¶é—´ | $O(|V|+|E|)$ | $O(|E|\cdot \log|V|)$  | $O(|E|\cdot |V|)$    |

### å¤„ç†éš¾é—®é¢˜(P, NP and NPC)

Pã€NPã€NPCå®šä¹‰åŠèŒƒå›´

## æœŸæœ«è€ƒè¯•æ¦‚è¿°

### è€ƒè¯•æ—¶é—´

2021å¹´1æœˆ11æ—¥(å‘¨äºŒ)ï¼š10:20-12:20

### è€ƒè¯•é¢˜å‹

* å¡«ç©ºé¢˜ Ã—4
  * å‡ é“ä¸»æ–¹æ³•è®¡ç®—ã€æ£®æ—å’Œæ ‘çš„è¾¹æ•°ç›®
* åˆ¤æ–­é¢˜ Ã—4
  * NPç›¸å…³ï¼ˆæ­£ç¡®ã€é”™è¯¯ã€æ— æ³•åˆ¤æ–­ï¼‰
* ç®—æ³•è¿è¡Œå®ä¾‹é¢˜ Ã—1
  * ä»¥æ‹“æ‰‘æ’åºä¸ºä¾‹
* ç®—æ³•è®¾è®¡é¢˜ Ã—4

1. åˆ†æ²»ï¼šä¸€ä¸ªâ€å±€éƒ¨æœ€å¤§å€¼â€œä¾‹é¢˜
2. åŠ¨æ€è§„åˆ’ï¼šä¸€ä¸ªè¯¦ç»†çš„å¼€è®¾åœ°ç‚¹çš„é¢˜ï¼Œè®¾è®¡åŒæŒ‡é’ˆç”¨äºæ›´æ–°c[i]çš„å€¼
3. è´ªå¿ƒï¼šé€‰ä¸€å®šé¢å€¼çš„ç¡¬å¸

