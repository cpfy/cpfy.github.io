计算机网络 笔记

ps：罗的ppt全是英文且杂乱，参考了刘秩的分章节、CS-Notes

## 第1节 课程介绍

协议、架构、多样性，各种综述等

最终成绩：平时成绩10% + 期末考试成绩90%

平时成绩：课后作业及课堂考勤综合考评

## 第2节 网络概述

#### 分组/包（Packet）

packet：包括header、payload。即报文与报头

Packets are a chunk of bits with：

* Payload：meaningful only to the endpoints
* Header：meaningful to the network and endpoint

一些定义

* Bandwidth： number of bits sent (or received) per unit time (bits/second or bps)
  “width” of the link
* Propagation delay： time it takes a bit to travel along the link (seconds)
  “length” of the link
* 时延带宽积：Bandwidth-Delay Product (BDP)： bits/time x propagation delay (bits)
  “capacity” of the link

传输时延 Packet Delay = (Packet Size / Link Bandwidth) + Propagation Delay

#### 地址与命名

基本定义：

* Network address： where host is located
* Network name： which host it is

address与name，以及二者映射。此步骤由Domain Name System （DNS） 域名解析系统完成

#### 路由（routing）

* 控制面：计算转发表的机制。
  * 固有全局：必须知道拓扑结构以便于计算
  * Routing算法是控制面的一部分
  * 时间尺度：每个网络事件
* 数据平面：使用这些表实际转发包。
  * 固有本地：只依赖于到达包和本地路由表。
  * 转发机制是数据面的一部分
  * 时间尺度：每一个到达包

每个plane有相应的challenge

对于data plane，需要在10ns内完成以下任务：

* Parse packet (extract address, etc.)
* Look up address in forwarding table
* Update other fields in packet header (if needed)
* Update relevant internal counters, etc.
* Send packet to appropriate output link

#### 统计复用

统计复用：静态资源复用。如OS的CPU、云计算

具有假设：流的峰值小于峰值的和。peak of aggregate load is << aggregate of peak loads

【p30的一张图】

统计多路复用仅仅意味着您没有为绝对最坏的情况做准备。相反，你共享资源，并希望峰值率不会同时出现

两个复用的方法：

电路交换/分组交换

1. 预留，任意情况下都不能用。通过电路交换（circuit switching）【p35图介绍此方法】
2. best-effort方法。通过（packet switching）

为每个packet独立分配资源，路径？

##### 定义

* Circuit switching： resources shared between flows currently in system
  * Reserve the peak demand for a flow
  * But don’t reserve for all flows that might ever exist
* Packet switching： resources shared between packets currently in system
  * Resources given out on packet-by-packet basis
  * Never reserve resources

##### 效率比较

从应用角度看：

Circuits offer better application performance (reserved bandwidth)

More predictable and understandable (w/o failures)

Also a very intuitive abstraction in support of business models!

**Packet switching is typically more efficient**

后者处理“突发情况”，峰值等效果较好。

以应用程序的峰值传输速率与平均传输速率之间的比率为特征。有些应用的峰值与平均比率相对较小。语音应用的峰值与平均比率可能为3：1左右。数据应用程序往往是突发的。比率大于或等于100是常见的。这就是为什么电话网络使用预订而互联网不使用的原因!

四个评价维度：

* As an abstraction to applications (endhosts)
* Efficiency
* Handling failures
* Complexity of implementation

##### 优缺点

.电路开关的优点：。更好的应用性能（预留带宽）更容易预测和理解（无故障）。分组交换的优点：。更好的效率。更快的启动到第一个包交付。更简单的实现（避免了交换机中逐流的动态状态管理）

##### 瞬时过载

<img src="计算机网络 笔记.assets/image-20220307211654980.png" alt="image-20220307211654980" style="zoom: 67%;" />

p66的Transient Overload问题：处理方式，排队queue

加入queue后的时延： packet delay = transmission delay + propagation delay + queueing delay

#### 包的生命周期

* 源有一些数据要发送到目的地
* 将其分成若干个包：每个包都有一个有效负载和一个报头。
* 数据包沿着链路传输。
* 到达一个开关;交换机将数据包转发到下一跳。
  * 可能switch处有缓冲区，或丢弃
* 最后一步不断重复，直到我们到达目的地……
  * 或被丢弃、遗失

【挑战】拥塞控制（Congestion control），若深入了解，涉及复杂的 `排队论` 问题

本学期的话题：

* How do we name endhosts on the Internet? (naming)
* How do we address endhosts? (addressing)
* How do we map names to addresses? (mapping names to addresses)
* How do we compute forwarding tables? (routing control plane)
* How do we forward packets? (routing data plane)
* How do hosts communicate reliably? (reliable packet delivery)
* How do sources know at what rate they can send packets? (congestion control)
* How to download content efficiently  (HTTP and the web)

## 第3节 网络概述2

### 模块化

> Modularity based on abstraction is the way things are done.	– Barbara Liskov, Turing lecture
>

* 将系统分解为更小的单元（提供“关注点分离”）
* 在计算机科学中扮演着至关重要的角色
* 关键在于找到正确的模块化

一个类比的例子：CEO_A寄快递给CEO_B

<img src="计算机网络 笔记.assets/image-20220309212813663.png" alt="image-20220309212813663" style="zoom:80%;" />

相应将整个过程分为五段：

* **应用层**（L7）：Applications
* **传输层**（L4）：Reliable (or unreliable) data delivery
* **网络层**（L3）：Best-effort global packet delivery
* **数据链路层**（L2）：Best-effort local packet delivery
* **物理层**（L1）：Physical transfer of bits

事实上，在OSI的标准分类中共有7层，第5层Session会话层，第6层Presentation。但一般将其并入Application应用层。

### 协议

**不同系统的对等层（peer layers）之间的通信是由协议定义的。**

> 罗：标准化？——> 固有思维，好用就行，先实际用起来
> 对等的层之间才规定协议，协议双方是对等的层级。

协议指的是：

* 双方关于如何通信的协议
* 定义通信的**语法**
* 之后是**语义**概念（如：“首先是一个你好，然后是一个请求…”）
* 协议存在于许多级别，硬件和软件由各种标准组织（IETF, IEEE, ITU）定义。

#### 协议种类

<img src="计算机网络 笔记.assets/image-20220309214426403.png" alt="image-20220309214426403" style="zoom:80%;" />

* 中间的网络层仅有一项协议 `IP` ，但其实是一系列协议组组成。
* 中间协议最少，两侧多，因此也被叫做酒杯模型、细腰模型
* 对每一层而言：依赖于下面的一层、支持上面的一层、独立于其他层
* 每层中的协议有多个版本：接口有所不同、组件选择使用哪个底层协议

### 传输过程

网络中的下面的三层可在任何地方实现（各个switch），上面的两层只在主机hosts上实现。

五层网络与设备对应关系：

![image-20220309214941517](计算机网络 笔记.assets/image-20220309214941517.png)

#### 端口（Port）

【Q】当收到一个包，如何知道是发给哪个应用的？通过端口号。

* 交换机/路由器有**物理端口**：链路连接到交换机的位置。
* 操作系统支持**逻辑端口**：应用程序连接到操作系统网络栈的位置

#### 套接字（Socket）

* Socket：一种连接应用程序进程到网络栈的操作系统机制
* 当一个应用程序想要访问网络时，它会打开一个套接字，这个套接字与一个端口相关联
* 该端口号被操作系统用来将传入的数据包导向其相关的套接字
* socket是通信真正的端点

示意图：

![image-20220309215334235](计算机网络 笔记.assets/image-20220309215334235.png)

#### 传输流程

![image-20220309215531218](计算机网络 笔记.assets/image-20220309215531218.png)

* 其中，routers之间的传输、routers与switch之间的同层次可采用不同协议（图中的SONET与Ethernet）

#### 报头

在传输时，数据包包含了多个报头：

![image-20220309215743781](计算机网络 笔记.assets/image-20220309215743781.png)

* 向底层运输时，在头部添加新的报头；向顶层解析时，去除报头信息。

## 第4节 端到端原则

> End-to-End Principle
>

### 传输可靠性

* 解决方案1：使每个步骤可靠(需要网络来处理可靠性)
* 解决方案2：允许不可靠的步骤，但做端到端检查（end-to-end check），并在必要时重试（不假设网络是可靠的）

评估两种方案的优劣基于：正确性、性能两个方面

两个关于可靠性的想法：

1. 网络可以从故障中恢复，这样，只要有一条路径存在，两个端点就可以通信。
2. 网络故障不应干扰端点语义

第二个要求意味着我们必须采用解决方案2(不能依赖网络)。

#### 丢包率

![image-20220311165900763](计算机网络 笔记.assets/image-20220311165900763.png)



对于一个上图所示的从A到B的网络传输：

* 如果每条链路的丢包率为10%，我们有10条链路，那么端到端失败率（E2E failure rate）为 65 %
* 如果链路实现了两次重传怎么办?每条链路的丢包率降低到0.1%，端到端错误率为 1%

所以减少链路传输的丢包率可以大幅降低整体传输流程（现在的准确率都非常高，大概7个99%的量级？）

在网络中实现的可靠性功能：

* 不会降低主机实现的复杂性
* 会增加网络的复杂性
* 是否可以在所有应用程序上增加开销，即使它们不需要功能
* 然而，在网络中实现可以提高某些情况下的性能，如高损耗链路

#### 端到端原则

对该原则定义不一，有三种解释：

`Only-if-Sufficient` 解释

* 不要在系统的较低级别实现某个功能，除非它可以在这个级别完全实现
* 除非你能消除主机的负担，否则不要自找麻烦

`Only-if-Necessary` 解释

* 不要在网络中实现任何可以由主机正确实现的东西
* 使网络层绝对最小化
  * 这种端到端加密的解释胜过了性能问题
  * 增加灵活性，因为较低的层保持简单

`Only-if-Useful` 解释

* 如果主机能够正确地实现功能，那么在较低的层次上实现它只是为了提高性能
* 但是，只有当它不给不需要该功能的应用程序带来开销时，才会这样做
* 在决定在何处放置功能时，这个标准通常会严重地考虑性能

三种解释的评价：

![image-20220312101621320](计算机网络 笔记.assets/image-20220312101621320.png)

概括：

* 在哪里实现功能是不平凡的
  * 端到端原则塑造了我们如何思考权衡!
* 重要的是：记住这是论点（argument），而不是规则（rule）
  * 尽管每个人都同意可靠性应该主要在主机中实现

E2E原则忽略的内容：

* 除了用户，还有其他利益相关者
  isp关心他们网络的运营/安全，寻找新的创收功能
* 这些功能更容易在网络中实现，想想防火墙。
* 更简单，因为这是isp控制的!它们不控制主机，所以它是否能在主机中实现并不重要;它不会
* 入侵检测系统，负载均衡器，NAT…

#### Fate-Sharing 设计

* 在分布式系统中存储状态时，将其与依赖于该状态的实体放在一起
* 失败可能导致临界状态丢失的唯一方法是，如果关心临界状态的实体也失败了，在这种情况下，这并不重要
* 通常认为流状态应该保持在终端主机上，而不是在路由器内部。而不是电路交换

架构设计的智慧：

* 分层提供了一个清晰的关注点分离，因此**支持创新**！（协议可替代，更有竞争）
* 端到端原则将不必要的状态和功能排除在网络之外，因此**允许Internet扩展**！（其余功能留给终端做，从而实现“智能终端”）

> 以上是End to end 论文idea

### 网络设计目标

> Clark, D. (1988, August). The design philosophy of the DARPA Internet protocols. In Symposium proceedings on Communications architectures and protocols (pp. 106-114).

列出一堆设计目标：

1. Connect existing networks
2. Robust in face of failures
3. Support multiple types of delivery services  (I.e., multiple types of applications)
4. Accommodate a variety of networks
5. Allow distributed management of resources
6. Easy end host attachment
7. Cost effective
8. Allow resource accountability

相反：构建最低公分母服务！架构灵活性拒绝：可靠性，性能保证，认证，诊断，…

一些其他重要的因素：安全、隐私、可用性、资源共享、ISP层次关心因素（政策、经济效益、价值分配等）

## 第5节 Routing #1

### 路由器 Router

多个节点通信，若两两连接，需要线太多，router减少网络连接与管理的复杂性

如何处理path？跳数最短并不一定时延最短

* Good的路径有多种衡量方式
* 不可有随机路径
* 不可把packet发给所有人
* 需能够适应各种拓扑结构（此处为一些美国国内、校园、企业、数据中心的网络拓扑结构举例）

#### 基本结构

需要存储目的地表：（NextHop或Port格式）

| Dst  | NextHop | Port |
| ---- | ------- | ---- |
| A    | R1      | 0    |
| B    | R3      | 1    |
| C    | R3      | 1    |
| D    | R4      | 2    |

此方法叫基于目的的路由（destination-based routing/forwarding）

#### 作用与功能

Routers做的事情：

* 转发（Forwarding）
  * 查表，发送包到邻居
  * 转发是本地的
  * data plane 负责
  * 时间尺度：每一个分组（ns单位）
* 按路径发送（Routing）
  * 与其他routers交流，决定如何为了forwarding计算表
  * Global的，必须知道全部目的地，不只是local
  * control plane的责任
  * 时间尺度：每个网络事件（network event），或每个 failure

一种Delivery Trees的方法

* NextHop变为一个指向相邻的箭头，所有箭头构成一棵树，以A为根节点

* 所有的路径构成有向Delivery tree
* 必须覆盖到全部节点

#### 路由状态的有效性

* 本地routing state是一个在单一router中的表（需要一种global类型的评估，不知道是否有效））
* 需要Global State，所有路由中的表的集合
* 路由协议的目的：计算valid state。也就是观察packets能否到达目的地

一个路线是有效的，当且仅当：无dead ends、无loops

* dead ends：死路，没有往外去的链接（next-hop）
* loops：循环，一个packet在一组同样的节点间重复流转

充分性：若无loops与dead ends，相当于有向非循环树，可证明是valid的

必要性：。。。

#### ？？？

* Hosts总体上不参与路由。大多情况下，hosts有一个默认路由【？？？？】
* routers也可能是一个合法的目的地

验证有效性时

* 聚焦于一个目的地（忽略全部其它hosts与routing state）
* 2
* 移除未用到的links
* 观察是否是最小生成树？

#### ？？？

距离矢量协议，设定的更新及连接规则：

* 每个router编号，获得一个magic number
* 之后给每个相邻的neighbour为自己的数加一，若数更小，更新num并指向新的router
* 一些可能导致错误的做法：忘记magic number、邻居未更新数字或连接、有人说谎

## 第6节 Routing #2

### routing与router的分类

分为域间与域内路由（Interdomain 与 Intradomain）

每一个团体（如大学、云主机、区域服务商）内部有内部路由，团体间依靠Border连接

* Intradomain路由：或多或少意味着在单个网络内进行路由(技术上是一个“自治系统”)，所使用的协议通常被称为IGPs或内部网关协议
* Interdomain路由：网络间路由(ASes)，将许多网络绑定到Internet中的路由粘合剂。使用的协议称为EGPs或外部网关协议（External Gateway Protocols）

### 最小代价路由

（Least-Cost Routing）

* 目标1：路由可行、有效（work）。不可有loop或dead ends
* 目标2：在某些方面“good”。最小化一些坏的因素如cost

对代价的定义：

* 代价可以指每一条边具有特定代价，寻找代价和最小的路径
* 另一种方式下，每一跳认为代价是1，即每经过一条边代价均为1

最小代价：

* 是一个避免循环的简单方法
* 最小代价路由基于目的地的（destination-based）
* 形成一颗最小生成树（因此必然无循环）

### 平凡与静态路径

（Trivial and Static Routes）

* 平凡路径：指一些无趣的、免费获得的、易被忽视的路径。
  * 例如，一条前往自己本身的路线；or 仅有一个邻居，路线上只能从那里经过
* 静态路线：操作者手工设置，多为特定目的。
  * 因为hosts不参与路由协议，通过已经添加好的静态路线表格来索引（见下图）
  * 路由器不需知道主机在哪里？知道主机地址即可

![image-20220323205547336](计算机网络 笔记.assets/image-20220323205547336.png)

### 距离-向量协议

（Distance-Vector Protocols）

#### 基本定义

简单介绍：

* 在互联网中已经有悠久历史（以及1969年的ARPANET 阿帕网）
* “原型”的D-V协议是RIP（Routing Information Protoco，路由信息协议）。
* 与Bellman-Ford最短路径算法有很强的关系。介于普通的Bellman-Ford协议和有用的路由协议之间

具体方法为：

* 设定表格，包含到哪个目的地Dst、经过的下一个节点路由Next、以及代价Cost
* 每隔X秒间隔向邻居发送，进行表格的更新

![image-20220323211149407](计算机网络 笔记.assets/image-20220323211149407.png)

【Q】如果处理多个host的情况？依然能很好处理。

更新路线的规则。如果：

* 目的地不在表中——加入表中
* 当前路线距离 > 广播宣传的距离 + 到邻居的距离——替代为当前新距离
* 广播来自已经记录的下一跳——替换新距离

可靠性：

* 路由器的计时器不会彼此同步!
* 在偏移计时器、包丢失、触发更新之间，广告可以以许多顺序出现。
* 在下面的例子中，我将展示可能发生的事情....这并不意味着它们总是会发生!
* 我通常会忽略触发更新，因为它们会使行为推理复杂化

#### 水平分割&计数到无穷

* 水平分割：若某一路径断裂，重新广播的过程中可能导致路径指向错误。
  * 解决方案：水平分割。指从自己处学的最优路径避免告诉原路由
* 计数到无穷：循环时，hop计数无穷上升。
  * 解决方案：为设定一个最大值停止，认为此时为无穷大、不可达

新增节点间连接的情况：Nxt, Cost能够与原先相比后及时更新，处理的很好。

一个特点：好消息传得快，坏的慢（说与生活中类似？）

#### 失效links处理

增加一列TTL（Time To Live），指一个有限的最大时间的值，随时间更新（减少）。

通过周期性的advertisements恢复补充；当未收到更新，期满、并移除此路由

至p157：作用是能够自行处理断路情形，并一段时间后建立新的连接

## 第7节 Routing #3

（接上节）

#### Poison

![image-20220323090254941](计算机网络 笔记.assets/image-20220323090254941.png)

TTL到0后，Nxt, Cost更新为None, $\infty$ 。并把此信息传播给邻居

* 关键理念：代替不宣传路线的方式，积极地宣传你没有路线
* 通过宣传一个不可思议的高成本来做到这一点
* 这个路由应该像其他路由一样传播，毒害其他正在使用它的路由器的入口
* 比等待暂停要快得多！

但是此方法对定时传播效果不好，有可能大面积且极快地传播dead routes。

#### Poison Reverse

类似但更激进的水平分割机制。令循环状态一直保持，直到下一次广播

### 更多触发事件

* 我们知道，表的更改应该触发我们发送更新
* 也可以用来处理其他事件....
* 有时我们可以检测到一条链路变为可用，立即发送新的邻居广告，不需要等待定时器
* 有时我们可以检测到当一个链接失败，立即毒害所有使用该链接的表项，如果有的话，发布新被毒害的表项!

### 链路状态路由

> Link-State Routing

与Distance-Vector工作方式差别很大。主要区别：

* 距离向量：全局计算(分布在所有节点上)。使用本地数据(仅来自自身和它的邻居)
* Link-State Routing：本地局部计算，使用全局数据(来自网络的所有部分)

Populating Tables：

* 每个router仅仅影响下一跳节点
* 其他路由器必须找到“兼容”的路径
* 如果：最小化相同的成本；所有费用均大于0；所有路由器都同意拓扑
* 考虑到所有这些，甚至不需要实现相同的算法

![image-20220323220134133](计算机网络 笔记.assets/image-20220323220134133.png)

每个路由器：

* 获取所有链路的状态和所有目的地的位置
* 使用全局信息来构建完整的图形（只需将所有的链接/目的地信息粘贴到一个图表中）
* 找到从自身到图上每个目的地的路径，用一些如Dijkstra寻找路径算法
* 在这些路径中使用第二个跳来填充它的转发表

#### 全局分享信息

如何知道邻居：通过自我介绍；路由器周期性地向邻居发送hello信息

#### Flooding

问题：网络出现一个或多个循环时，Packet在网络中无限循环。

一种（为了知道所有节点的邻居）解决方案：

* 当本地信息(如邻居)发生变化时，发送给所有邻居
* 当收到邻居发来的信息报文时，发送给所有其他邻居。除非您已经看到了这个信息包(在这种情况下，丢弃它)
* 如何知道这是不是你第一次看到它?简单的解决办法是：路由器在更新时输入序列号

序列号具体方案

* 每个路由器都有自己的序列号，当它发送路由消息时，它将其放入包.....中然后增加它。
* 每个路由器都会跟踪从其他路由器看到的最大序列号
  * 如果它看到一个具有较小/相等序列号的更新....更新是旧的-放弃它
  * 如果它看到一个更大的序列号更新..更新是新的-记住序列号和flood update到所有其他邻居

#### 收敛

使用简单的Dijkstra算法，当出现断路情况，仍可能出现循环发送的情况

收敛延迟的来源：检测故障的时间；淹没链路状态信息的时间(与网络直径成正比)；重新计算路径/表的时间。

在收敛的周期内：可能出现Deadends、报文循环发送、到达目的地址的报文顺序不一致（不会引起语义问题，但会造成性能问题）

### 学习交换机 & 生成树协议

> （Learning Switches & The Spanning Tree Protocol）
>

一种不同的填写表的方法——学习交换机

* 使用数据包投机地填充的表。
* 不需要“播种”静态条目!
* 在链路层(L2)的路由中非常常见。
* 许多人会说它不是路由，但如果它看起来像一只鸭子，嘎嘎叫起来像一只鸭子，并像鸭子一样填写转发表....(我可能把这个比喻搞砸了。)

具体方法为：A到B发包，若不知道目的地，就指数级乱传，路上标记Dst为A的路径；B收到并返回后，同样路径上标记；之后再发送直接即可得知到B的路径

此方法的问题：

* 当目的地未知时，发生Floods
* 拓扑结构有循环时，floods具有问题

此方法的一种伪代码写法：

```python
on arrival of packet from neighbor previous_hop：
	# Learn
    table[packet.source].next_hop = previous_hop
    table[packet.source].ttl = five_minutes
    
    # Forward
    if packet.destination in table：
        next_hop = table[packet.destination].next_hop
        if next_hop == previous_hop：
        	packet.drop() # why?
        else：
        	packet.forward_to(next_hop)
    else： # destination not in table
    	packet.flood_to_neighbors(except=previous_hop)
```

## 第8节 寻址与转发

> Flat Address Forwarding
>

源路由（Source Routing）

利用层次化寻址

##### IPv4

独一无二的32位的数字，作为地址

原则上分为两部分，前缀（prefix）与后缀（suffix），前缀为网络部分，后缀为主机部分。如23+9=32。

当时设计时，认为网络不会太多，认为顶多256个networks。因此让前面8bit是网络部分，后24位为主机部分

##### IP地址架构-1981

1981年时：路由知道网络ID，但不知道个人主机

IP路由查找：

* 识别前缀用于转发，检测地址种类与网络ID
* 转发表包含：类+网络的List、一些固定的前缀长度（8/16/24）
* IP地址aa.bb.cc.dd的class B，class+neiwork部分是aa.bb，在表中找他

* 表依然很大，200万 class C networks

#### CIDR

假设一个具有50个电脑的网络，分配6比特作为主机地址， $2^5<50<2^6$ ；其余26比特作为网络前缀部分用。

为减少浪费，引入**子网掩码**来表示：255.255.255.192。含义为前26位均置1，后6位均置0。

==why？转换方式是？==

##### 层次化IP分类

层次地址结构

层次地址分配

层次地址与路由可扩展性

##### 子网

B类地址仍然有6万多，仍然比较大。容易乱，如何有序且容易管理

不是直接每一个一个划分，而是分为大块，每一组分一大块，之后每组内部自己分剩下的

（AT&T的A类地址往下分的示意图）



如何处理multi-homing问题？即多个分配合并（++++示意图）

掩码长度越长，放在靠前，选择最长的匹配，称为**最长掩码匹配**。

==有个10.1.2.0/24； 10.1.1.2/31 是啥意思==

##### 如何获取一个IP地址

DHCP协议（Dynamic Host Configuration Protocol，动态获取地址协议）

一个host申请找地址用，找DHCP服务器借地址用，给他分。一般为了防止来源不可追踪、干坏事，给同一个人分同一个IP，便于网络活动分析。（但此前提是地址空间足够大）

IPv4与IPv6的区别：一个夸张的说法，地球上的每个沙子可分10个

## 第9节 IP Addressing

> 从CS-Notes 网络层 摘录许多内容

### IP 数据报格式

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt="img" style="zoom:67%;" />

格式解释：

* **版本** : 有 4（IPv4）和 6（IPv6）两个值
* **首部长度** : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5
* **区分服务** : 用来获得更好的服务，一般情况下不使用。
* **总长度** : 包括首部长度和数据部分长度。
* **生存时间** ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。
* **协议** ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。
* **首部检验和** ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。每个路由器检查校验码Checksum，若错误则丢弃本报文
* **标识** : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。
* **片偏移** : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。

### IP 地址编址方式

IP 地址的编址方式经历了三个历史阶段：

- 分类
- 子网划分
- 无分类

#### 1. 分类

由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。

IP 地址 ::= {< 网络号 >, < 主机号 >}

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/cbf50eb8-22b4-4528-a2e7-d187143d57f7.png" alt="img" style="zoom:67%;" />



#### 2. 子网划分

通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。

IP 地址 ::= {< 网络号 >, < 子网号 >, < 主机号 >}

要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。

注意，外部网络看不到子网的存在。

#### 3. 无分类

无分类编址 **CIDR** 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。

IP 地址 ::= {< 网络前缀号 >, < 主机号 >}

CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。

CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。

一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 **构成超网** 。

在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。

### IP分片

Fast Path与Slow Path

* Fast Path：不用经过CPU，不用查，直接转
* Slow Path：处理QS？分片等情况，需要转给CPU用。现在路由器也可处理分片，但目前一般太大直接扔了，并返回错误信息？

#### MTU

每一个网络都有MTU（Maximum Transmission Unit）

Header中的标识位：M指More Fragment。M=0表示后边无其他分片；M=1表示还有

例如一片长度3820的报文，若MTU=2000，如下分割：

1. （Length=2000，M=1，Offet=0）
2. 1820。仍然有Header，之后将两部分组装

### 地址转换与NAT

地址的Size不够用

* 长期可能需要更多ip地址。（有一个增长示意图，超过100w）
* 需要128位的IPv6地址

专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。

在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/2719067e-b299-4639-9065-bed6729dbf0b.png" alt="img" style="zoom: 67%;" />

* 私有地址与公共网络的连接？公共网络里不会转发私有地址的分组，不会跨越，保障安全性。

* NAT方法：将源地址与源端口替换，目的则不变，保证二者一一映射。

* 例如源地址：198.2.4.5；换为目的地址10.2.2.2

NAT的挑战：

* 在会话中必须保持一致
* 仅仅对特定应用有效
* 在对等应用中的处理（谁是server？）

## 第10节 域间路由

### AS自治系统

AS（Autonomous System），即自治系统。关注区域之间通信策略

AS的特征：

* AS是一个处于单一管理控制下的网络。例如AT&T、UCB、IBM、法国电信等
* 通常被称为“域”
* 每个AS都被分配一个唯一的AS号(ASN)。例如，ASN 25是由IANA (Internet assigned Numbers Authority)及其下属组织UCBAssigned的

分类：

* 存根（Stub）：仅代表直接相连的用户、公司、大学等发送/接收数据包的自治系统。
* 传输者（Transit）：代表其他自治系统携带数据包，可以在规模上有很大的差异(全球的，区域的，等)

AS之间的商业关系：

* AS X与AS Y之间的关系：customer、provider、peer
* 顾客向provider支付；peer之间不互相付钱的（假设交换的流量大致相等）

* **Business** 是域间路由的核心
* AS基本按等级分为Tier1-Tier3几种情况，全世界的Tier1层级的AS不超过10个数

示意图：

<img src="计算机网络 笔记.assets/image-20220401141854967.png" alt="image-20220401141854967" style="zoom:67%;" />

### 目标与挑战

#### 目标

2个基本 + 2个扩展：

* 找到有效的路径：无loop与deadend
* 找到好的路径：最小代价路径

* 可伸缩性：路由必须扩展到整个互联网!
* 策略遵从性：路由必须反映业务目标

#### 可伸缩性

* 路由器必须能够到达任何目的地。给定任何目的地址，必须知道“下一跳”
* 幼稚型：为每个目的地设置一个条目。32位IPv4地址多达232个目的地!以及每个目的地的路由更新!

从IP地址设计到可伸缩性

* 当分配匹配拓扑层次时，分层寻址有助于路由可伸缩性
* 问题：可能无法对“多归属”网络进行地址聚合。多归属→多于一个提供商
* 可伸缩路由聚合中的两种竞争力量。聚合减少了路由表项的数量，多归属增加了路由表项的数量
* 目前路由表100w（IPv6？）

（一种聚合的例子）聚合前的表：

<img src="计算机网络 笔记.assets/image-20220401144111095.png" alt="image-20220401144111095" style="zoom:67%;" />

聚合后：

<img src="计算机网络 笔记.assets/image-20220401144133929.png" alt="image-20220401144133929" style="zoom:67%;" />

聚合在以下情况下效果最好：

* 通过相同路径到达的目的地组可以用一个下一跳总结多个路径，这取决于**拓扑结构**
* 这些组被分配为连续的地址。可以用一个路由表项汇总多个地址，取决于**地址分配**

#### 策略遵从性

希望：基于策略能够自由选择路线、自治性、隐私

典型策略的两个原则：

1. 如果你没有得到报酬，不要接受运输流量!
2. 在发送流量时节省/赚钱。宁愿退回流量给客户；如果必须的话，只有通过供应商发送。

自治与隐私

* AS们希望自治：希望有选择自己政策的自由，要选择自己的内部路由协议
* AS们希望隐私：不要向别人明确宣布这些选择
* 策略是我们想要实现的目标;自治和隐私是我们“如何”实现它的要求

#### 总结

域间路由的设计必须支持以上policy，同时尽可能满足自治性与隐私

边界网关协议（**BGP**，Border Gateway Protocol）是目前采用的方法

### 处理方法

基本设置与准备

* 节点是自治系统(Autonomous system)，每个自治系统的内部结构是隐藏的
* 目的地是IP前缀(12.0.0.0/8)
* 链路代表物理链路和业务关系

Routing算法的选择，可以是LS或DV两种

* LS不提供隐私-广播所有的网络信息
* LS限制自治——需要在度量、算法上达成一致
* DV是一个不错的起点。但不是为了执行政策而设计的，逐目的地路由更新作为实现策略的钩子?
* 结果：BGP对DV进行了扩展，以适应policy

#### BGP的基本思想

如下两个方法间循环

1. AS向一个或多个IP前缀发布（**输出**）其最佳路由
2. 每个AS**选择**它所听到的为前缀发布的“最佳”路由

策略将决定选择哪些路由发布以及发布哪些路由(稍后详细介绍)

#### BGP与DV的四个核心区别

1. BGP可以对目的地址进行聚合。出于可扩展性考虑，BGP可以针对不同的前缀进行路由聚合
2. 不选择最短路径。BGP根据策略选择最佳路由，而不是基于最小开销
3. 从距离向量到路径向量的思想。
   * 距离向量向每个目的地的发送距离度量；
   * 路径向量发送每个目的地的整个路径；
   * 好处在于容易避免循环，且能够根据整个路径制定策略

![image-20220401150700900](计算机网络 笔记.assets/image-20220401150700900.png)

4. 有选择性地广播路径。由于策略的原因，AS可以选择不发布到目的地的路由。因此，即使图是连通的，也不能保证可达性

#### Gao-Rexford 规则

在选择时：

* 当选择到目的地的路由时，广播路径的选择顺序为：customer > peer > provider
* 在实际操作上，AS使用附加规则
* 按如下优先级顺序进行：
  * 赚钱/省钱(G-R规则)
  * 最大化性能
  * 最小化网络带宽的使用

G-R规则的具体Export Policy

| 所发布的目的地前缀 | 出口路线                                  |
| ------------------ | ----------------------------------------- |
| Customer           | 所有人（包括Providers、Peers、Customers） |
| Peer               | 仅Customers                               |
| Provider           | 仅Customers                               |

若全部的AS遵循G-R规则，那么路线是**valley free**的，也就是指仅单一顶点

##### 规则的含义

* 对于AS图有两种假设（即将出现），如果所有的AS都遵循Gao-Rexford，我们可以保证：
  * 可达性：任意两个AS间可以通信
  * 汇聚：所有路由器都同意位于路径上
* 以上构成了保持稳定状态
* 以上并不能作一般性policy的保证

两个假设

1. 客户-供应商关系图是无循环的。
   * 不能具有 $A\to B\to C$ 和 $C\to A$ （当前节点指向先前节点）
   * 意味着可以在层次结构中安排provider
   * 注意：peer之间关系循环是允许的，可以(A-B, B-C, C-A)
2. 从任何一个AS开始，沿着提供商链，能够到达Tier 1 AS。Tier 1指的是一组彼此对等的提供者AS

#### Recap

* 策略是通过选择我们选择的路线和导出的路线来实现的
* Gao-Rexford规则告诉我们选择/导出哪些路线可以赚钱/省钱
* 当你遵守G-R规则时，好事就会发生

### BGP的详细设计

#### speak BGP

speak BGP 的含义：

* 实现BGP协议标准。详见：http://tools.ietf.org/html/rfc4271
* 指定与其他BGP“speaker”交换的消息类型和语法
* 以及如何处理这些消息。例如，“当你收到一个BGP更新，做..

BGP的几种类别

* **eBGP**：不同AS边界路由器之间的BGP会话。交换到不同目的前缀的路由
* **iBGP**：在同一AS内的，边界路由器与其他路由器之间的BGP会话。将外部学习到的路线向内部分发
* **IGP**：“内部网关协议”=域内路由协议。提供内部可达性，如OSPF, RIP

<img src="计算机网络 笔记.assets/image-20220401171407792.png" alt="image-20220401171407792" style="zoom:67%;" />

#### 简单总结

* AS中的每个路由器都有两个路由表：
  * 从IGP：到所有内部目的地的下一跳
  * 从iBGP：出口路由器到所有外部目的地
* 对于内部地址，只需使用IGP。 Entry &lt;内部目的地，内部下一跳>
* 对于外部位置：使用iBGP查找出口使用IGP查找出口，即前往出口路由器的下一跳

#### 路由更新

* 将新路由通知邻居
* 通知邻居更新旧路由
* “撤销”一条现在不活跃的路线
* 格式为：**\<IP prefix: route attributes\>**

##### 路由属性

* 描述路由的一般机制。用于路由选择/导出决策
* 有些属性是local（即AS内private）。eBGP公告中不包含
* 一些属性通过eBGP路由通告进行传播
* BGP中有许多标准化的属性

四个属性为：AS path、local preference、MED、IGP cost

（1）属性1：AS path

列出路由通告所经过的所有ase的路径向量(按倒序)，载于路线通告内

<img src="计算机网络 笔记.assets/image-20220401183251843.png" alt="image-20220401183251843" style="zoom: 80%;" />

（2）Local Preference

* 用于在不同的AS路径之间进行选择
* 仅在一个AS中本地存在；仅在iBGP消息中携带
* 值越高，越优先

<img src="计算机网络 笔记.assets/image-20220401183459417.png" alt="image-20220401183459417" style="zoom:80%;" />

（3）MED

MED，指多出口鉴别器（Multi-Exit Discriminator）。当AS通过2个或更多的链接相互连接时，用于指定一个前缀距离宣布它的链接有多近

AS宣布前缀集MED(越低越好)；AS接收前缀（可选！）使用MED选择链路

![image-20220401183841246](计算机网络 笔记.assets/image-20220401183841246.png)

（4）IGP Cost

为局部参数，在一个AS内部，每个路由器基于IGP 选择它最近的边界路由器。

用一个名词形容：“hot potato” routing——烫手山芋路由

![image-20220401184131817](计算机网络 笔记.assets/image-20220401184131817.png)

* 注意，IGP的选择可能会与MED冲突，即选出的离最近的出口的路线+MED后不是最优的
* 由此，也可能导致循环

##### 选择策略

1. make/save money: LOCAL PREF (cust > peer > provider)
2. maximize performance: length of ASPATH
3. minimize use of my network bandwidth: “hot potato”, MED

| 优先级 | 规则       | 评论                                      |
| ------ | ---------- | ----------------------------------------- |
| 1      | Local Pref | 选则最高的                                |
| 2      | AS Path    | 选择最短的AS path长度                     |
| 3      | IGP path   | 最小化IGP Cost                            |
| 4      | MED        | MED preferred                             |
| 5      | Router ID  | 作为tie-breaker的最小的下一跳路由器IP地址 |

### BGP的问题

主要问题包括4点：

* 安全性。因此有路由劫持等安全性问题
* 性能。不一定好
* 容易错误配置
* 可达性和收敛性

#### 安全性

* AS可以声称提供一个它们实际上没有路由到的前缀(黑洞流量)。与策略或路径矢量无关的问题
  * 解决方案：让AS们“证明”它们有路径
* 注意：AS可能会沿着不同于发布的路由转发数据包。但此问题更难修复

#### 性能

AS路径长度可能具有误导性

![image-20220402162457968](计算机网络 笔记.assets/image-20220402162457968.png)

#### 易于配置错误（misconfiguration）

* BGP协议既臃肿又不明确
  * 大量的属性
  * 在如何设置和解释属性方面有很多余地
  * 必须允许自治，多样化的政策
  * 但这也给了运营商足够的自由。
* 大部分配置都是手动的和特别的
* 这种方法从根本上是有缺陷的
  * disjoint 每个路由的配置，实现AS范围内的策略
  * 现在强烈的兴趣改变这一切!(后来使用SDN方法）

#### 可达性与收敛性

* 如果G-R假设和规则成立，则可达性和收敛性就得到了保证
* 如果没有：没有/很少保证！

策略振荡



## 第11节 reliable transport

> 2022-04-06 第六周 Wedn

关于ack、超时重传、滑动窗口等问题

> 摘自CS-Notes

### TCP的三次握手

<img src="计算机网络 笔记.assets/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt="img" style="zoom: 50%;" />

假设 A 为客户端，B 为服务器端。

- 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
- A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
- B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
- A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
- B 收到 A 的确认后，连接建立。

**三次握手的原因**

第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

### TCP的四次挥手

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt="img" style="zoom: 67%;" />

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。

- A 发送连接释放报文，FIN=1。
- B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
- 当 B 不再需要连接时，发送连接释放报文，FIN=1。
- A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
- B 收到 A 的确认后释放连接。

**四次挥手的原因**

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

**TIME_WAIT**

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

- 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

### TCP 可靠传输

TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。

一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：
$$
RTTs=(1-a)*RTTs+a*RTT
$$
其中，$0 \leq a ＜ 1$ ，RTTs 随着 a 的增加更容易受到 RTT 的影响。

超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：
$$
RTO=RTTs+4*RTT_d
$$
其中 $RTT_d$ 为偏差的加权平均值。

### TCP 滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

<img src="计算机网络 笔记.assets/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" alt="img" style="zoom:67%;" />

### TCP 流量控制

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

## 第12节 Transport Layer

传输层的作用

* 弥合两者之间的差距 
  * 应用设计者想要的抽象 
  * 网络可以轻松支持的抽象 
* 为应用层提供通用服务 
  * 代表应用与网络打交道 
  * 代表网络处理应用程序 
* 可以内置于应用程序中，但通用的实现方式使应用程序的开发更加容易 

应用程序可以自己写传输协议、拥塞控制等，但太麻烦，不过Chrome自己做传输协议，快！



需要实现的功能

* 解除多路复用（Demultiplexing） ：识别这个数据的应用（逻辑端口，第3讲）
* 可靠性 
* 从数据包到应用级抽象的转换 ：例如，在bytestreams和数据包之间。
* 避免被发送方超载：限制有多少数据来到我身边 
* 避免网络过载：限制我产生多少数据 



### Demultiplexing

前期过程：

* 当一个应用程序想要访问网络时，它打开一个与逻辑端口（**logical port**）相关的套接字（**socket**）。
* 操作系统将一个端口号（**port number**）映射到其相关的套接字上
* 数据包携带一个目标地址和端口号
* 操作系统将传入的数据包传递给套接字（与数据包的目的端口相关的进程 

因此，应用层不需关心网络具体实现，更高层级的抽象

对应用的抽象

* 可靠的有序的字节流传输（TCP）
  * 发送方和接收方之间的逻辑 "管道"
  * 发送方将字节插入管道
  * 它们按顺序出现在接收方（到应用程序）。
* 单个消息传递（UDP）
  * 不可靠（应用程序负责重新发送）。
  * 信息仅限于单个数据包 

#### 选择窗口

* 挑选窗口大小 **W** 以平衡三个目标
  *  利用网络容量（"填充管道"）。
  * 但不要让接收器超载（流量控制）。
  * 也不要让链接过载（拥堵控制） 
* 对于第一个目标，我们说：W x pkt_size - RTT x B
  * RTT是往返时间，B是瓶颈BW
  * 这是对W的期望大小的一个上限（**upper bound**）

#### 不让接收过载

* 考虑到接收方的传输层 
* 可能会收到不按顺序排列的数据包，但只能按顺序将它们传递给应用程序。
* 因此，接收方必须对传入的不符合顺序的数据包进行缓冲 
  * 必须继续这样做，直到所有 "丢失 "的数据包到达 
* 必须确保接收器不会用完缓冲器 

因此，这被称为Flow Control



* 发送方的传输层实现了一种拥塞控制算法，动态地计算发送方在瓶颈链路BW中的份额。
* TCP称其为发送方的拥塞窗口（cwnd， **congestion window**）
* 通过计算来平衡多个目标
  * 使我的性能最大化
  * 不使任何链路过载（避免丢包）
  * 同时与其他发送方 "公平 "分享带宽



* 选择窗口大小W以平衡三个目标
* 充分利用网络容量（"填充管道"）。
* 但不要让接收方过载（流量控制）。
* 不要让链接超载（拥堵控制）。
* 第一个目标：W - RTT x B。
* 第二：W ~ 接收方的广告窗口 
* 第三：W - 发件人的拥塞窗口（cwnd）
* 窗口大小被设置为上述的最小值

在实际中，

* 一个发件人的cwnd应该<=RTT x B。
* 而发送方很难发现B。
* 因此，窗口大小是以下的最小值。
  * 在发送方计算的拥塞窗口 
  * 接收方的广告窗口 

#### UDP和TCP的特点

> 摘自CS-Notes

* 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。
* 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。

#### UDP格式

<img src="计算机网络 笔记.assets/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg" alt="img" style="zoom: 50%;" />

首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

### TCP

* TCP提供一个可靠的、有序的字节流 （**reliable, in-order, bytestream**）
* 可靠性需要保持状态 
  * 发送方：已发送但未被ACK的数据包，相关的定时器 
  * 接收者：无序的数据包
* 每个字节流被称为一个连接（**connection**）或会话 
  * 每个都有自己的连接状态 
  * 状态是在主机中，而不是在网络中!

#### 端口

* 16位TCP和UDP的端口地址空间 
* 一些端口是 "众所周知的"（0-1023）。
  * 例如，ssh:22, http:80 
  * 服务可以监听知名端口 
  * 客户端（应用程序）知道服务器上适当的端口 
* 其他端口是 "短暂的"（多数为1024-65535）。
  * 给予客户（随机）的

#### TCP报文格式

<img src="计算机网络 笔记.assets/image-20220408145701957.png" alt="image-20220408145701957" style="zoom:67%;" />

![image-20220408152020096](计算机网络 笔记.assets/image-20220408152020096.png)

- **序号** ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。
- **确认号** ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
- **数据偏移** ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
- **确认 ACK** ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
- **同步 SYN** ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。
- **终止 FIN** ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
- **窗口** ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

#### TCP可靠传输

我们以前的许多想法，有一些关键的区别 

* 序列号是字节偏移量 
* 使用滑动窗口：飞行中最多有W个连续的字节 
* 使用累积的ACKs 
* 由超时和重复ACK触发的重传 
* 单一定时器，用于窗口的左侧 
* 窗口大小是cwnd和广告窗口的一个函数 
  * 在丢失的情况下，用重复ACK来扩大窗口（未来的讲座）。
* 如何从RTT测量中计算超时



* 以前我们关注的是数据包。
  * 数据包有数字 
  * ACKs指的是这些数字 
  * 窗口大小以数据包的数量表示
* TCP关注的是字节数。因此。
  * 数据包由其携带的字节识别
  *  ACKs指的是收到的字节数
  * 窗口大小用字节数表示 

==图片p45==

#### ACK与序列号

* 发送者发送数据包 
  * 数据以序列号X开始
  * 数据包包含B字节：$X, X+1, X+2, ....X+b-1$ 
* 收到数据包后，接收方发送一个ACK 
  * 如果所有X之前的数据已收到：ACK确认X+B(因为这是下一个预期字节) 
  * 如果收到的最高连续字节是一个较小的值Y：ACK确认Y+1（因为TCP使用累积ACK）。

示例，一个一个发

* 发送者：seqno=X, length=B 
* 接收者：ACK=X+B
* 发送方：seqno=X+B, length=B
* 接收者。ACK=X+2B
* 发送方：seqno=X+2B, length=B 
* 下一个数据包的Seqno与最后一个ACK字段相同

#### TCP连接的建立和初始序列号

==p61关于ISN==

> 可参见L11
>

##### SYN损失和网络下载 

* 用户点击一个超文本链接 
  * 浏览器创建一个套接字并进行 "连接"。
  * 连接 "触发操作系统传输SYN
* 如果SYN丢失... 
  * 3-6秒的延迟：可能非常长
  * 用户可能变得不耐烦
  * ....，再次点击超链接，或点击 "重新加载"。

* 用户触发了 "连接 "的 "中止 "过程 
  * 浏览器创建一个新的套接字和另一个 "连接"。
  * 本质上，迫使更快地发送一个新的SYN数据包! 
  * 有时非常有效，而且页面很快就会出现

Tearing Down the Connection

## 第13节 拥塞控制

在1980s年代的TCP，

* 发送率只受流量控制的限制

  * 丢弃的数据包被发送者重传，反复出现！

* 导致1986年10月的 "拥塞崩溃"

  > 在198686年10月，互联网出现了一系列 "拥堵崩溃 "中的第一个。在此期间，从LBL到加州大学伯克利分校的数据吞吐量（站点之间相隔400码，有两个IMP跳转）。400码和两个IMP跳）从32Kbps下降到40bps。我们对我们被这种突然的千分之一的带宽下降所吸引，开始调查为什么事情变得如此糟糕。特别是，我们想知道4.3BSD（Berkeley UNIX）的TCP 是否有问题，或者是否可以对其进行调整，以便在糟糕的网络条件下更好地工作。
  > 这两个问题的答案都是 "是"。

Jacobson的方法

* 对TCP现有协议的增量扩展
  * 来源根据观察到的数据包丢失情况来调整其窗口大小 
* 一个务实而有效的（如果不是完美的）解决方案 
  * 不需要升级路由器或应用程序
  * 在BSD的TCP实现中加入几行代码的补丁 
* 迅速被采用，并成为事实上的方法
* 广泛的研究和改进 

### CC的目标与挑战

关于拥塞控制

* 从根本上说，是一个资源分配问题
  * 流被分配到一个路径上的链路BW的份额
* 但比传统的资源分配更复杂。
  * 改变一条链路的分配会产生全局影响
  * 而且我们在每个流量到达/离开时都会改变分配
  * 没有任何一个实体可以完全了解或完全控制! 
  * (例外：在一个数据中心内) 

* 在我们的环境中，分配是高度相互依赖的

**CC的意义**

* 从资源分配的角度来看
  * 数据包延迟和丢失率低
  * 高链路利用率
  * "公平 "分享流量

* 从系统的角度来看
  * **实用**：可扩展、分布式、自适应等。

### Design Space

【方法一】保留 

【方法二】定价/优先权 

* 不为出价最高的用户/优先级用户丢弃数据包 
* 根据当前的拥堵程度向用户收费 
* 需要支付模式

【方法三】动态调整 

* 主机动态地了解当前的拥堵程度 
* 相应地调整他们的发送速率 
* 对于如何实现这一基本理念有许多选择

在实践中，动态调整的**通用性**已被证明是强大的！

示意图：

<img src="计算机网络 笔记.assets/image-20220413083651798.png" alt="image-20220413083651798" style="zoom: 67%;" />

### 解决方案的组成部分

一些需考虑的问题：

* 选择初始速率（先从一个较小的速率开始，称为Slow Start）
* 检测拥堵情况（丢包、延迟增加、）
* 对拥堵（或不拥堵）做出反应（增加/减少规则）

CC的分类

* 基于主机的CC（Jacobson的原始TCP方法，本课主要介绍）
  * 没有来自路由器的特殊支持 
  * 主机根据路由器的**隐性**反馈来调整速率 
* 路由器协助的CC
  * 路由器向主机发出拥堵信号 
  * 主机根据路由器的**明确**反馈来选择速率

#### 速率调整

* CC设计的一个关键部分！
* 决定了主机如何快速适应可用带宽的变化 
* 决定了如何有效地消耗BW
* 决定了如何分享带宽（公平）

其调整的目标为

* **效率**：链接带宽的高利用率
* **公平性**：每个流量都得到平等的份额

##### 四种可能的调整办法

* AIAD：温和上升，温和下降
* **AIMD**：温和增加，快速减少 
* MIAD：快速增加，温和减少 
* MIMD：快速增加，快速减少

选择AIMD的原因

* 发送太多信息的后果比发送太少更糟糕
  * 太多：丢弃和重传数据包 
  * 太少：吞吐量降低 
* 一般的方法
  * 在不拥挤的情况下温和增长（探索） 
  * 拥堵时迅速减少

##### 简单模型与证明

效率与公平：一个简单的模型（一个是二者相加为1，另一个是x1、x2相等）

<img src="计算机网络 笔记.assets/image-20220413085453216.png" alt="image-20220413085453216" style="zoom: 67%;" />

考虑四种方法

* AIAD：经过一通操作，回到我们开始的地方！X1和X2之间的差距没有任何变化。**没有收敛到公平的程度**
* MIMD：**没有收敛到公平的程度**
* MIAD：X1变为0，MIAD是最大的不公平！
* AIMD：最好的结果（见下图）

<img src="计算机网络 笔记.assets/image-20220413090034858.png" alt="image-20220413090034858" style="zoom: 80%;" />

### TCP的解决方案简图

每个源都独立地运行以下程序：

* **慢速启动**以找到初始速率
* 试着在某个时间段内以R的速率发送
  * 在这段时间内是否遇到了拥塞**损失**？
    * 如果是，就**乘法**降低R（2倍）
    * 如果没有，则以**加法**方式增加R (+1) 
  * 重复

最后传输速率“锯齿”图

<img src="计算机网络 笔记.assets/image-20220413093059361.png" alt="image-20220413093059361" style="zoom:80%;" />

==常用ftp、http等端口的号记一下。p215页==



## 第14节 TCP拥塞控制

拥塞判断

* 重传定时器超时：现在通信线路的传输质量一般都很好，因传输出差错而丢弃分组的概率是很小的（远小于 1 %）。只要出现了超时，就可以猜想网络可能出现了拥塞。
* 收到三个相同（重复）的 ACK：个别报文段会在网络中丢失，预示可能会出现拥塞（实际未发生拥塞）

### 控制算法

控制算法

* 慢开始 (slow-start)
* 拥塞避免 (congestion avoidance)
* 快重传 (fast retransmit)
* 快恢复 (fast recovery)

#### 慢开始

思路：由小到大逐渐增大拥塞窗口数值

拥塞窗口 cwnd  控制方法：在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个 SMSS 的数值

<img src="计算机网络 笔记.assets/image-20220415140556677.png" alt="image-20220415140556677" style="zoom: 67%;" />

传输轮次

* 使用慢开始算法后，每经过一个传输轮次 (transmission round)，拥塞窗口 cwnd 就加倍。
* 一个传输轮次所经历的时间其实就是往返时间 RTT。

#### 拥塞避免

慢开始门限 ssthresh 的用法如下：

* 当 cwnd < ssthresh 时，使用慢开始算法
* 当 cwnd > ssthresh 时，停止使用慢开始算法而改用**拥塞避免算法**
* 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法

拥塞避免算法的思路：让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。

无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（重传定时器超时）：

* ssthresh = max(cwnd/2，2)
* cwnd = 1
* 执行慢开始算法

![image-20220415141554651](计算机网络 笔记.assets/image-20220415141554651.png)

#### 快重传

* 采用快重传FR (Fast Retransmission) 算法可以让发送方**尽早知道发生了个别报文段的丢失**。
* 快重传 算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。
* 发送方**只要一连收到三个重复确认**，就知道接收方确实没有收到报文段，因而应当立即进行重传（即“快重传”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。
* 使用快重传可以使整个网络的吞吐量提高约20%。 

#### 快恢复

* 当发送端收到连续三个重复的确认时，由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是执行快恢复算法 FR (Fast Recovery) 算法：
  1. 开始门限 ssthresh = 当前拥塞窗口 cwnd / 2 ；
  2. 新拥塞窗口 cwnd = 慢开始门限 ssthresh ；
  3. 开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。 

（例子见上图中的点5）

##### 另一种解释

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

<img src="计算机网络 笔记.assets/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png" alt="img" style="zoom: 50%;" />

### 其他思想

#### AIMD

可以看出，在拥塞避免阶段，拥塞窗口是按照线性规律增大的。这常称为“加法增大” AI (Additive Increase)。
当出现超时或3个重复的确认时，就要把门限值设置为当前拥塞窗口值的一半，并大大减小拥塞窗口的数值。这常称为“乘法减小”MD (Multiplicative Decrease)。
二者合在一起就是所谓的 AIMD 算法。

#### 发送窗口的上限

发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定：

发送窗口的上限值 = Min [rwnd, cwnd]                

#### 随机早期检测 RED

使路由器的队列维持两个参数：队列长度最小门限 $TH_{min}$ 和最大门限 $TH_{max}$。
RED 对每一个到达的分组都先计算平均队列长度 LAV 。

1. 若平均队列长度小于最小门限 THmin，则将新到达的分组放入队列进行排队。
2. 若平均队列长度超过最大门限 THmax，则将新到达的分组丢弃。
3. 若平均队列长度在最小门限 THmin 和最大门限THmax 之间，则按照某一概率 p 将新到达的分组丢弃。

RED 将路由器的到达队列划分成为三个区域： 

![image-20220415142957921](计算机网络 笔记.assets/image-20220415142957921.png)

但在实际中，路由器只有几ns时间处理，还需要费时的随机数等，效果不太好

* 多年的实践证明，RED 的使用效果并不太理想。
* 2015年公布的 RFC 7567 已经把 RFC 2309列为陈旧的，并且不再推荐使用 RED。
* 对路由器进行主动队列管理 AQM 仍是必要的，AQM 实际上就是对路由器中的分组排队进行智能管理，而不是简单地把队列的尾部丢弃。

## 第14节 应用层

> 一些小节不讲，考试也很少内容

客户/服务器的概念

### 6.4 万维网

定义：大规模的、联机式的信息储藏所

url的一般形式：

```html
<协议>://<主机>:<端口>/<路径>
```

HTTP协议使用持续连接

HTTP报文结构、语法

### 域名系统

> 根域名服务器a-m rootservers.net
>
> 递归 or 迭代两种访问方法

DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。

域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。

<img src="计算机网络 笔记.assets/b54eeb16-0b0e-484c-be62-306f57c40d77.jpg" alt="img" style="zoom:67%;" />

DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：

- 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。
- 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。

### 常用端口

|       应用       | 应用层协议 | 端口号  | 传输层协议 |            备注             |
| :--------------: | :--------: | :-----: | :--------: | :-------------------------: |
|     域名解析     |    DNS     |   53    |  UDP/TCP   | 长度超过 512 字节时使用 TCP |
| 动态主机配置协议 |    DHCP    |  67/68  |    UDP     |                             |
| 简单网络管理协议 |    SNMP    | 161/162 |    UDP     |                             |
|   文件传送协议   |    FTP     |  20/21  |    TCP     |  控制连接 21，数据连接 20   |
|   远程终端协议   |   TELNET   |   23    |    TCP     |                             |
|  超文本传送协议  |    HTTP    |   80    |    TCP     |                             |
| 简单邮件传送协议 |    SMTP    |   25    |    TCP     |                             |
|   邮件读取协议   |    POP3    |   110   |    TCP     |                             |
| 网际报文存取协议 |    IMAP    |   143   |    TCP     |                             |

### Web 页面请求过程

#### 1. DHCP 配置主机信息

- 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
- 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
- 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
- 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF，将广播到与交换机连接的所有设备。
- 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
- 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
- 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

#### 2. ARP 解析 MAC 地址

- 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
- 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
- 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
- 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
- DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
- 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
- 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

#### 3. DNS 解析域名

- 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
- 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
- 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
- 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
- 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

#### 4. HTTP 请求页面

- 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
- 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
- HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
- 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
- HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
- 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

## 第15节 数据链路层

网络中的主机、路由器等都必须实现数据链路层

### 3.1 数据链路层的几个共同问题

#### 3.1.1 数据链路和帧

链路与“数据链路”基本定义及区别

* 链路
* 数据链路

物理链路和逻辑链路

帧：点对点信道的数据链路层协议数据单元

#### 3.1.2 三个基本问题

1. ==封装成帧==：一段数据前后添加首部和尾部，首尾的一个重要作用是**帧定界**，SOH与EOT等控制字符
2. ==透明传输==：指实际存在的事物看起来像不存在一样。具体方法为每个`SOH`和`EOT`之间插入转义字符`ESC`，此方法称为**字节填充**
3. ==差错检测==：bit在传输过程中出现**比特差错**。

差错相关：

* 一段时间内，传输错误的比特占所传输比特总数的比率称为**误码率（BER）**

* 目前广泛采用**循环冗余检验CRC**（Cyclic Redundancy Check）的检错技术

* 每组数据k个比特，n位冗余码，共同构成一个帧。这种为了进行检错而添加的冗余码称为**帧检验序列FCS**（Frame Check Sequence）

### 3.2 点对点协议PPP

按信道类别分类，分为广播信道、点对点信道

#### 3.2.1 PPP协议的特点

略，10个【p79】

#### 3.2.2 PPP协议的帧格式

帧格式：

- F 字段为帧的定界符
- A 和 C 字段暂时没有意义
- FCS 字段是使用 CRC 的检验序列
- 信息部分的长度不超过 1500

<img src="计算机网络 笔记.assets/759013d7-61d8-4509-897a-d75af598a236.png" alt="img" style="zoom:80%;" />

字节填充

零比特填充：使用SONET/SDH链路时使用同步传输

#### 3.2.3 PPP协议的工作状态

链路静止？

### 3.3 使用广播信道的数据链路层

#### 3.3.1 局域网的数据链路层

局域网的主要特点：网络为一个单位所拥有，且地理范围和站点数目均有限

信道复用技术：（==考的多+英文==）

* 频分复用：所有主机在相同的时间占用不同的频率带宽资源
* 时分复用：所有主机在不同的时间占用相同的频率带宽资源
* 波分复用：光的频分复用
* 码分复用：
  * 为每个用户分配 m bit 的码片，并且所有的码片正交
  * 当接收端使用码片对接收到的数据进行内积运算时，结果为 0 的是其它用户发送的数据，结果为 1 的是用户发送的比特 1，结果为 -1 的是用户发送的比特 0。
  * 码分复用需要发送的数据量为原先的 m 倍。
* （无？）统计时分复用：时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送

动态媒体接入控制

#### 3.3.2 CSMA/CD协议

CSMA/CD含义：载波监听多点接入/碰撞检测（Carrier Sense Multiple Access With Collision Detection）

* **多点接入**：总线型网络
* **载波监听**：每个站点在发送数据之前检测总线上是否有其他计算机正在发送。即用电子技术检验总线上有没有其他计算机发送的数据信号
* **碰撞检测**：计算机边发送数据边检测信道上的信号电压大小。若发现出现碰撞，立即停止发送，等待一段随机时间继续发送

把总线上的单程端到端传播时延记为  $\tau$ ，最先发送数据帧的站，发送后至多需要 $2\tau$ 时间即可知道是否发生碰撞

退避算法的规定：

1. 基本退避时间取为争用期 $2\tau$（具体时间为 $51.2\mu s$）
2. 从整数集合 $[0,1,...,(2^k-1)]$ 中随机选出一个数，记为r，重传应推后的时间为r倍的争用期。k的计算：$k=\min[\text{重传次数},10]$
3. 重传16次仍不成功，丢弃、报告

使用CSMA/CD协议时，不能同时进行发送和接收，只能进行**双向交替通信（半双工通信）**

#### 3.3.3 使用集线器的星型拓扑

早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。

#### 3.3.4 以太网的信道利用率

局域网，主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场

定义参数a，指以太网单程端到端时延 $\tau$ 与**帧的发送时间** $T_0$ 之比：
$$
a=\frac{\tau}{T_0}
$$

## 第16节 Continue

#### 3.3.5 以太网的MAC层

48位MAC地址，组织唯一标识符（24位）+扩展唯一标识符

MAC三种广播类型：单播、广播、多播

适配器检查MAC地址

* 所有适配器能够识别单播地址和广播地址
* 只有目的地址才能使用广播地址和多播地址

以太网V2的MAC帧格式

==说某个东西必考==，结合某个部分？？

#### 3.4 扩展的以太网

##### 3.4.1 在物理层扩展以太网

不推荐

##### 3.4.2 在数据链路层扩展以太网

碰撞域：又称冲突域，指网络中一个站点发出的帧会与其他站点发出的帧产生碰撞或冲突的那部分网络。碰撞域越大，则发生碰撞的概率越高

##### 交换机

早期使用网桥，现在使用以太网交换机

* 交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。

下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧，主机 B 回应该帧向主机 A 发送数据包时，交换机查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 2 的映射。

![img](计算机网络 笔记.assets/a4444545-0d68-4015-9a3d-19209dc436b3.png)



#### 3.5 高速以太网



第9章 无线网络和移动网络



9.1 无线局域网WLAN

IEEE 802.11是一个有固定基础设施的无线局域网的国际标准

热点

移动自组网络

主要问题：路由选择协议、多播、安全



9.1.2 802.11局域网的MAC层协议

不能简单搬用XSMA/CD协议，两个原因：

* r1
* r2

用CSMA/CA协议，增加一个碰撞避免CA（Collision Avoid）功能

帧间间隔IFS（InterFrame Space）：所有站发送后必须等待一段很短时间才能发送下一帧

* SIFS，短的帧间间隔

CSMA/CA协议的原理：xxxx

虚拟载波监听的机制：让源站将要占用信道的时间通知给所有其他站，以便使其他所有站在这一段时间都停止发送数据

算法的四点核心归纳：

> 1234



2.对信道进行预约

使用RTS和CTS帧



9.1.4 802.11局域网的MAC帧

三种类型：控制帧、数据帧和管理帧



关于802.11数据帧的地址。四个地址字段

地址1：目的地址；地址2：源地址；地址3：真正的源地址



## 第17节 ARP & ICMP

> 地址解析协议ARP（Address Resolution Protocol）
>
> 网际控制报文协议 ICMP（Internet Control Message Protocol）

### ARP协议

#### 引言

IP报文传输过程 = n段物理网的穿越+段间中继

网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/66192382-558b-4b05-a35d-ac4a2b1a9811.jpg" alt="img" style="zoom:80%;" />

ARP 实现由 IP 地址得到 MAC 地址。

#### 地址转换

发送：NI_Snd(U32 toIP, SDU *packet)

* **toIP：**物理网上接收方的IP地址，可为目的IP、网关IP或广播组播IP
* **SDU：**IP报文及辅助信息
* **IP期望：**单播、组播或广播，都由物理网完成

接收方类似。NI用于IP到物理地址的转换

#### 地址解析技术

* 静态ARP：事先记录IP网上各地址物理地址与IP地址。（早期方法）

* 动态地址解析：广播询问、延迟报文发送等

ARP协议规范

* ARPreq广播发送，ARPresp单播发送
* 发送ARP报文时，始终填上自己的绑定
* IP层发送报文时，根据ARP表不同情况处理

ARP实现

* 独立的ARP服务访问点：0806

* ARP静态、动态结合
  * Y：动态，已解析，有生命期
  * S：静态，无生命期
  * T：正在解析，有小的生命期
  * N：无绑定
* 队列存放待发的IP报文
* 生命期：已解析120-300s、正在解析1-30s

动态ARP安全性弱点：例如一台机器可帮别的机器ARP应答，则发生地址欺骗，发到目的机器的物理地址对应成了该机器的物理地址

#### ARP工作原理

每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。

如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

<img src="计算机网络 笔记.assets/8006a450-6c2f-498c-a928-c927f758b1d0.png" alt="8006a450-6c2f-498c-a928-c927f758b1d0" style="zoom: 67%;" />

#### RARP 反向地址解析

与ARP协议非常相似：广播RARP请求，用RARP相应决定自己的IP地址

RARP实现：建立RARP服务器，响应RARP请求。为防止服务器失效，设置若干备份服务器，进行协调

RARP的替代物：BOOTP、DHCP，均在IP层上实现

### ICMP协议

ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e3124763-f75e-46c3-ba82-341e6c98d862.jpg" alt="img" style="zoom: 50%;" />

ICMP 报文分为差错报告报文和询问报文。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png" alt="img" style="zoom: 50%;" />

ICMP常见应用

* **Ping：**Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。
* **Traceroute：**Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。

## 第18节 网络安全

> 第 7 章 网络安全
>

###  7.1 网络安全问题概述

分为被动、主动攻击

![image-20220429145302769](计算机网络 笔记.assets/image-20220429145302769.png)

恶意程序：计算机病毒、计算机蠕虫、特洛伊木马、逻辑炸弹

计算机网络安全的内容：保密性、安全协议的设计、访问控制 

### 7.2 两类密码体制

* 对称密钥密码体制：加密密钥与解密密钥是相同的密码体制，又称常规密钥密码体制。
  * 采用数据加密标准 DES

* 公钥密码体制：公钥密码体制使用不同的加密密钥与解密密钥
  * 加密密钥(即公钥) PK 公开，解密密钥(即私钥或秘钥) SK 保密
  * 公钥加密算法的开销较大
  * 解密过程： $D_{SK_B}(Y)=D_{SK_B}(E_{PK_B}(X))=X$

### 7.3 数字签名

数字签名必须保证以下三点：

* **报文鉴别**——接收者能够核实发送者对报文的签名；
* **报文的完整性**——发送者事后不能抵赖对报文的签名；
* **不可否认**——接收者不能伪造对报文的签名。

![image-20220429150810931](计算机网络 笔记.assets/image-20220429150810931.png)

### 7.4 鉴别

许多报文并不需要加密但却需要数字签名，以便让报文的接收者能够**鉴别报文的真伪**

报文摘要算法：对比报文短得多的摘要H进行数字签名，防止报文被人恶意篡改

![image-20220429151413325](计算机网络 笔记.assets/image-20220429151413325.png)

实体鉴别：在系统接入的全部持续时间内，对和自己通信的对方实体**只需验证一次**。

攻击风险：

* 重放攻击：使用不重数（nonce）进行鉴别
* 中间人攻击：密钥分配等解决方案

### 7.5 密钥分配

* 设立**密钥分配中心 KDC** （Key Distribution Center）：给需要进行秘密通信的用户临时分配一个会话密钥（仅使用一次）
* 需要有一个值得信赖的机构——即**认证中心 CA** （Certification Authority），来将公钥与其对应的实体（人或机器）进行绑定(binding)。
* 认证中心一般由政府出资建立。

### 7.6 因特网使用的安全协议

#### 7.6.1 网络层安全协议

* IPsec
  * 鉴别首部 AH (Authentication Header)： AH鉴别源点和检查数据完整性，但不能保密。
  * 封装安全有效载荷 ESP (Encapsulation Security Payload)：鉴别源点、检查数据完整性和提供保密。 
* 安全关联 SA：使用 AH 或 ESP 之前，从源主机到目的主机建立一条网络层的逻辑连接。

#### 7.6.2 运输层安全协议

* 安全套接层 SSL（Secure Socket Layer）：对万维网客户与服务器之间传送的数据进行加密和鉴别
* 安全电子交易 SET（Secure Electronic Transaction）：专为在因特网上进行安全支付卡交易的协议

#### 7.6.3 应用层的安全协议

* PGP（Pretty Good Privacy）：一个完整的电子邮件安全软件包，包括加密、鉴别、电子签名和压缩等技术
* PEM（Privacy Enhanced Mail）：因特网的邮件加密建议标准

### 7.7 链路加密与端到端加密

* 采用链路加密的网络中，每条通信链路上的加密是独立实现的。通常对每条链路使用不同的加密密钥。 

* 端到端加密是在源结点和目的结点中对传送的 PDU 进行加密和解密，报文的安全性不会因中间结点的不可靠而受到影响。

### 7.8 防火墙

防火墙：由软件、硬件构成的系统，是一种特殊编程的路由器，用来在两个网络之间实施接入控制策略。
